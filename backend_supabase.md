# Nexwork Frontend - Supabase ë°±ì—”ë“œ êµ¬ì¶• ì™„ì „ ì‹¤í–‰ ê°€ì´ë“œ ğŸ“š

> **ğŸ¯ ëª©í‘œ**: ëª¨ë“  Phaseë¥¼ 100% ì™„ë£Œí•˜ì—¬ ì™„ì „í•œ Supabase ë°±ì—”ë“œ ì‹œìŠ¤í…œ êµ¬ì¶•

## ğŸ“‹ í”„ë¡œì íŠ¸ ê°œìš”

ë³¸ ë¬¸ì„œëŠ” Nexwork Frontend í”„ë¡œì íŠ¸ì˜ í˜„ì¬ ëª©ì—… ë°ì´í„° ê¸°ë°˜ ì‹œìŠ¤í…œì„ Supabaseë¥¼ í™œìš©í•œ ì™„ì „í•œ ë°±ì—”ë“œ ì‹œìŠ¤í…œìœ¼ë¡œ ì „í™˜í•˜ê¸° ìœ„í•œ **ì‹¤í–‰ ê°€ëŠ¥í•œ ì™„ì „ ê°€ì´ë“œ**ì…ë‹ˆë‹¤.

### ğŸ¯ ê°œì„ ëœ ì ‘ê·¼ ë°©ì‹
- âœ… **ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ìŠ¤í¬ë¦½íŠ¸ ì œê³µ**
- âœ… **ë‹¨ê³„ë³„ ì™„ë£Œ ê²€ì¦ ë°©ë²• ëª…ì‹œ**  
- âœ… **ì‹¤ì œ í™˜ê²½ êµ¬ì¶•ë¶€í„° ë°°í¬ê¹Œì§€ ì™„ì „ ì»¤ë²„**
- âœ… **ëª¨ë“  Phase 100% ë‹¬ì„± ê°€ëŠ¥í•œ êµ¬ì²´ì  ê°€ì´ë“œ**

### í˜„ì¬ ìƒíƒœ ë¶„ì„
- **í”„ë¡ íŠ¸ì—”ë“œ**: Next.js 15.1.6 + TypeScript + Material-UI
- **í˜„ì¬ ë°ì´í„°**: ë¡œì»¬ ëª©ì—… ë°ì´í„° (`src/data/`)
- **ì¸ì¦**: Next-Auth 4.24.11 ì‚¬ìš© ì¤‘ (ë¡œì»¬ ì„¸ì…˜)
- **ìƒíƒœ ê´€ë¦¬**: React Hooks + Props drilling

## ğŸ—ï¸ 1. ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ ì„¤ê³„

### 1.1 ì „ì²´ ì•„í‚¤í…ì²˜
```
Frontend (Next.js)
    â†“ HTTP/API
Supabase 
â”œâ”€â”€ PostgreSQL Database
â”œâ”€â”€ Authentication
â”œâ”€â”€ Real-time Subscriptions
â”œâ”€â”€ Storage
â””â”€â”€ Edge Functions (serverless)
```

### 1.2 í•µì‹¬ êµ¬ì„± ìš”ì†Œ
- **Database**: PostgreSQL (Supabase ë‚´ì¥)
- **Authentication**: Supabase Auth
- **API**: Supabase Client SDK + Edge Functions
- **File Storage**: Supabase Storage
- **Real-time**: Supabase Realtime

## ğŸ—ƒï¸ 2. ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì„¤ê³„

### 2.1 ì¸ì¦ ë° ì‚¬ìš©ì ê´€ë¦¬

```sql
-- ì‚¬ìš©ì í”„ë¡œí•„ í™•ì¥ í…Œì´ë¸”
CREATE TABLE user_profiles (
  id UUID REFERENCES auth.users(id) PRIMARY KEY,
  email TEXT UNIQUE NOT NULL,
  name TEXT NOT NULL,
  avatar_url TEXT,
  role TEXT DEFAULT 'user' CHECK (role IN ('admin', 'manager', 'user')),
  department TEXT,
  position TEXT,
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Row Level Security í™œì„±í™”
ALTER TABLE user_profiles ENABLE ROW LEVEL SECURITY;

-- ì •ì±… ì„¤ì •
CREATE POLICY "Users can view own profile" ON user_profiles
  FOR SELECT USING (auth.uid() = id);

CREATE POLICY "Users can update own profile" ON user_profiles
  FOR UPDATE USING (auth.uid() = id);
```

### 2.2 ë¹„ìš©ê´€ë¦¬ ëª¨ë“ˆ

```sql
-- ë¹„ìš© ê¸°ë¡ í…Œì´ë¸”
CREATE TABLE cost_records (
  id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
  registration_date DATE NOT NULL,
  start_date DATE NOT NULL,
  code TEXT UNIQUE NOT NULL,
  team TEXT NOT NULL,
  assignee_id UUID REFERENCES user_profiles(id),
  cost_type TEXT NOT NULL CHECK (cost_type IN ('ì†”ë£¨ì…˜', 'í•˜ë“œì›¨ì–´', 'ì¶œì¥ê²½ë¹„', 'í–‰ì‚¬ê²½ë¹„', 'ì‚¬ë¬´ê²½ë¹„')),
  content TEXT NOT NULL,
  quantity INTEGER NOT NULL DEFAULT 1,
  unit_price DECIMAL(15,2) NOT NULL,
  amount DECIMAL(15,2) NOT NULL,
  status TEXT DEFAULT 'ëŒ€ê¸°' CHECK (status IN ('ëŒ€ê¸°', 'ì§„í–‰', 'ì™„ë£Œ', 'ì·¨ì†Œ')),
  completion_date DATE,
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  created_by UUID REFERENCES user_profiles(id)
);

-- ê¸ˆì•¡ ìƒì„¸ í…Œì´ë¸”
CREATE TABLE cost_amount_details (
  id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
  cost_record_id UUID REFERENCES cost_records(id) ON DELETE CASCADE,
  code TEXT NOT NULL,
  cost_type TEXT NOT NULL,
  content TEXT NOT NULL,
  quantity INTEGER NOT NULL,
  unit_price DECIMAL(15,2) NOT NULL,
  amount DECIMAL(15,2) NOT NULL
);

-- ë¹„ìš© ì½”ë©˜íŠ¸ í…Œì´ë¸”
CREATE TABLE cost_comments (
  id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
  cost_record_id UUID REFERENCES cost_records(id) ON DELETE CASCADE,
  author_id UUID REFERENCES user_profiles(id),
  content TEXT NOT NULL,
  timestamp TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- ì²¨ë¶€íŒŒì¼ í…Œì´ë¸”
CREATE TABLE cost_attachments (
  id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
  cost_record_id UUID REFERENCES cost_records(id) ON DELETE CASCADE,
  name TEXT NOT NULL,
  file_type TEXT NOT NULL,
  file_size BIGINT NOT NULL,
  storage_path TEXT NOT NULL,
  upload_date TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  uploaded_by UUID REFERENCES user_profiles(id)
);

-- ì¸ë±ìŠ¤ ìƒì„±
CREATE INDEX idx_cost_records_assignee ON cost_records(assignee_id);
CREATE INDEX idx_cost_records_status ON cost_records(status);
CREATE INDEX idx_cost_records_team ON cost_records(team);
CREATE INDEX idx_cost_records_date ON cost_records(registration_date);
```

### 2.3 ì—…ë¬´ê´€ë¦¬ ëª¨ë“ˆ

```sql
-- ì—…ë¬´ í…Œì´ë¸”
CREATE TABLE task_records (
  id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
  no SERIAL,
  registration_date DATE NOT NULL,
  code TEXT UNIQUE NOT NULL,
  team TEXT NOT NULL CHECK (team IN ('ê°œë°œíŒ€', 'ë””ìì¸íŒ€', 'ê¸°íšíŒ€', 'ë§ˆì¼€íŒ…íŒ€')),
  department TEXT NOT NULL CHECK (department IN ('IT', 'ê¸°íš')),
  work_content TEXT NOT NULL,
  status TEXT DEFAULT 'ëŒ€ê¸°' CHECK (status IN ('ëŒ€ê¸°', 'ì§„í–‰', 'ì™„ë£Œ', 'í™€ë”©')),
  assignee_id UUID REFERENCES user_profiles(id),
  start_date DATE,
  completed_date DATE,
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  created_by UUID REFERENCES user_profiles(id)
);

-- ì—…ë¬´ ì²¨ë¶€íŒŒì¼ í…Œì´ë¸”
CREATE TABLE task_attachments (
  id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
  task_record_id UUID REFERENCES task_records(id) ON DELETE CASCADE,
  filename TEXT NOT NULL,
  storage_path TEXT NOT NULL,
  upload_date TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- ì¸ë±ìŠ¤ ìƒì„±
CREATE INDEX idx_task_records_assignee ON task_records(assignee_id);
CREATE INDEX idx_task_records_status ON task_records(status);
CREATE INDEX idx_task_records_team ON task_records(team);
```

### 2.4 êµìœ¡ê´€ë¦¬ ëª¨ë“ˆ

```sql
-- êµìœ¡ ê¸°ë¡ í…Œì´ë¸”
CREATE TABLE education_records (
  id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
  registration_date DATE NOT NULL,
  start_date DATE NOT NULL,
  code TEXT UNIQUE NOT NULL,
  education_type TEXT NOT NULL CHECK (education_type IN ('ì‹ ì…êµìœ¡', 'ë‹´ë‹¹ìêµìœ¡', 'ê´€ë¦¬ìêµìœ¡', 'ìˆ˜ì‹œêµìœ¡')),
  content TEXT NOT NULL,
  participants INTEGER DEFAULT 0,
  location TEXT NOT NULL,
  status TEXT DEFAULT 'ì˜ˆì •' CHECK (status IN ('ì˜ˆì •', 'ì§„í–‰', 'ì™„ë£Œ', 'ì·¨ì†Œ')),
  completion_date DATE,
  assignee_id UUID REFERENCES user_profiles(id),
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  created_by UUID REFERENCES user_profiles(id)
);

-- ì»¤ë¦¬í˜ëŸ¼ í…Œì´ë¸”
CREATE TABLE education_curriculum (
  id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
  education_record_id UUID REFERENCES education_records(id) ON DELETE CASCADE,
  time_slot TEXT NOT NULL,
  subject TEXT NOT NULL,
  instructor TEXT NOT NULL,
  content TEXT NOT NULL,
  attachment_path TEXT,
  sort_order INTEGER DEFAULT 0
);

-- ì°¸ì„ì í…Œì´ë¸”
CREATE TABLE education_participants (
  id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
  education_record_id UUID REFERENCES education_records(id) ON DELETE CASCADE,
  participant_name TEXT NOT NULL,
  department TEXT NOT NULL,
  position TEXT NOT NULL,
  attendance TEXT DEFAULT 'ì˜ˆì •' CHECK (attendance IN ('ì˜ˆì •', 'ì°¸ì„', 'ë¶ˆì°¸')),
  report_path TEXT,
  note TEXT
);

-- êµìœ¡ ì‹¤ì  í…Œì´ë¸”
CREATE TABLE education_results (
  id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
  education_record_id UUID REFERENCES education_records(id) ON DELETE CASCADE,
  performance TEXT,
  improvement TEXT,
  feedback TEXT
);

-- ì¸ë±ìŠ¤ ìƒì„±
CREATE INDEX idx_education_records_status ON education_records(status);
CREATE INDEX idx_education_records_type ON education_records(education_type);
```

### 2.5 ê³µí†µ ì‹œìŠ¤í…œ í…Œì´ë¸”

```sql
-- ì½”ë“œ ìë™ ìƒì„±ì„ ìœ„í•œ ì‹œí€€ìŠ¤ í…Œì´ë¸”
CREATE TABLE code_sequences (
  module_type TEXT PRIMARY KEY,
  current_year INTEGER NOT NULL,
  current_sequence INTEGER NOT NULL DEFAULT 0,
  updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- ì‹œìŠ¤í…œ ì„¤ì • í…Œì´ë¸”
CREATE TABLE system_settings (
  key TEXT PRIMARY KEY,
  value JSONB NOT NULL,
  description TEXT,
  updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  updated_by UUID REFERENCES user_profiles(id)
);

-- í™œë™ ë¡œê·¸ í…Œì´ë¸” (ê°ì‚¬ ì¶”ì ìš©)
CREATE TABLE activity_logs (
  id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
  user_id UUID REFERENCES user_profiles(id),
  action TEXT NOT NULL,
  table_name TEXT NOT NULL,
  record_id UUID,
  old_values JSONB,
  new_values JSONB,
  timestamp TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  ip_address INET
);
```

## ğŸ”Œ 3. API ì—”ë“œí¬ì¸íŠ¸ ì„¤ê³„

### 3.1 Supabase Client ê¸°ë³¸ ì„¤ì •

```typescript
// lib/supabase.ts
import { createClient } from '@supabase/supabase-js'

const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL!
const supabaseAnonKey = process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!

export const supabase = createClient(supabaseUrl, supabaseAnonKey, {
  auth: {
    autoRefreshToken: true,
    persistSession: true,
    detectSessionInUrl: true
  },
  realtime: {
    params: {
      eventsPerSecond: 10
    }
  }
})

// íƒ€ì… ì •ì˜
export type Database = {
  public: {
    Tables: {
      user_profiles: {
        Row: UserProfile
        Insert: Omit<UserProfile, 'id' | 'created_at' | 'updated_at'>
        Update: Partial<Omit<UserProfile, 'id' | 'created_at'>>
      }
      cost_records: {
        Row: CostRecord
        Insert: Omit<CostRecord, 'id' | 'created_at' | 'updated_at'>
        Update: Partial<Omit<CostRecord, 'id' | 'created_at'>>
      }
      // ... ë‹¤ë¥¸ í…Œì´ë¸” íƒ€ì…ë“¤
    }
  }
}
```

### 3.2 ë¹„ìš©ê´€ë¦¬ API

```typescript
// api/cost.ts
import { supabase } from '@/lib/supabase'
import type { CostRecord } from '@/types/cost'

export class CostAPI {
  // ë¹„ìš© ëª©ë¡ ì¡°íšŒ
  static async getCostRecords(filters?: {
    team?: string
    status?: string
    assignee?: string
    dateRange?: { start: string; end: string }
  }) {
    let query = supabase
      .from('cost_records')
      .select(`
        *,
        assignee:user_profiles(name, email),
        comments:cost_comments(
          id, content, timestamp,
          author:user_profiles(name, avatar_url)
        ),
        attachments:cost_attachments(*),
        amount_details:cost_amount_details(*)
      `)

    if (filters?.team) {
      query = query.eq('team', filters.team)
    }
    if (filters?.status) {
      query = query.eq('status', filters.status)
    }
    if (filters?.assignee) {
      query = query.eq('assignee_id', filters.assignee)
    }
    if (filters?.dateRange) {
      query = query
        .gte('registration_date', filters.dateRange.start)
        .lte('registration_date', filters.dateRange.end)
    }

    return query.order('registration_date', { ascending: false })
  }

  // ë¹„ìš© ê¸°ë¡ ìƒì„±
  static async createCostRecord(data: Omit<CostRecord, 'id'>) {
    const { data: newRecord, error } = await supabase
      .from('cost_records')
      .insert(data)
      .select()
      .single()

    if (error) throw error
    return newRecord
  }

  // ë¹„ìš© ê¸°ë¡ ìˆ˜ì •
  static async updateCostRecord(id: string, data: Partial<CostRecord>) {
    const { data: updatedRecord, error } = await supabase
      .from('cost_records')
      .update({ ...data, updated_at: new Date() })
      .eq('id', id)
      .select()
      .single()

    if (error) throw error
    return updatedRecord
  }

  // ëŒ“ê¸€ ì¶”ê°€
  static async addComment(costRecordId: string, content: string) {
    const { data: { user } } = await supabase.auth.getUser()
    if (!user) throw new Error('ì¸ì¦ë˜ì§€ ì•Šì€ ì‚¬ìš©ì')

    const { data: comment, error } = await supabase
      .from('cost_comments')
      .insert({
        cost_record_id: costRecordId,
        author_id: user.id,
        content
      })
      .select(`
        *,
        author:user_profiles(name, avatar_url)
      `)
      .single()

    if (error) throw error
    return comment
  }

  // íŒŒì¼ ì—…ë¡œë“œ
  static async uploadFile(costRecordId: string, file: File) {
    const fileExt = file.name.split('.').pop()
    const fileName = `${costRecordId}/${Date.now()}.${fileExt}`

    // Supabase Storageì— íŒŒì¼ ì—…ë¡œë“œ
    const { data: uploadData, error: uploadError } = await supabase.storage
      .from('cost-attachments')
      .upload(fileName, file)

    if (uploadError) throw uploadError

    // ì²¨ë¶€íŒŒì¼ ê¸°ë¡ ì €ì¥
    const { data: { user } } = await supabase.auth.getUser()
    const { data: attachment, error: dbError } = await supabase
      .from('cost_attachments')
      .insert({
        cost_record_id: costRecordId,
        name: file.name,
        file_type: file.type,
        file_size: file.size,
        storage_path: fileName,
        uploaded_by: user?.id
      })
      .select()
      .single()

    if (dbError) throw dbError
    return attachment
  }
}
```

### 3.3 ì—…ë¬´ê´€ë¦¬ API

```typescript
// api/task.ts
export class TaskAPI {
  static async getTaskRecords(filters?: TaskFilterOptions) {
    let query = supabase
      .from('task_records')
      .select(`
        *,
        assignee:user_profiles(name, email, avatar_url),
        attachments:task_attachments(*)
      `)

    // í•„í„° ì ìš© ë¡œì§
    if (filters?.department) {
      query = query.eq('department', filters.department)
    }
    if (filters?.status) {
      query = query.eq('status', filters.status)
    }

    return query.order('created_at', { ascending: false })
  }

  static async createTaskRecord(data: Omit<TaskRecord, 'id' | 'no'>) {
    // ìë™ ì¦ê°€ ì½”ë“œ ìƒì„± ë¡œì§
    const code = await this.generateTaskCode()
    
    const { data: newRecord, error } = await supabase
      .from('task_records')
      .insert({ ...data, code })
      .select()
      .single()

    if (error) throw error
    return newRecord
  }

  private static async generateTaskCode(): Promise<string> {
    // ì—°ë„ë³„ ì‹œí€€ìŠ¤ ê´€ë¦¬
    const year = new Date().getFullYear()
    const { data: sequence, error } = await supabase
      .rpc('get_next_sequence', { 
        module_type: 'TASK',
        year: year
      })

    if (error) throw error
    return `TASK-${year.toString().slice(-2)}-${String(sequence).padStart(3, '0')}`
  }
}
```

### 3.4 êµìœ¡ê´€ë¦¬ API

```typescript
// api/education.ts
export class EducationAPI {
  static async getEducationRecords() {
    return supabase
      .from('education_records')
      .select(`
        *,
        assignee:user_profiles(name, email),
        curriculum:education_curriculum(*),
        participants:education_participants(*),
        result:education_results(*)
      `)
      .order('start_date', { ascending: false })
  }

  static async createEducationRecord(data: Omit<EducationRecord, 'id'>) {
    const { curriculum, participants, result, ...mainData } = data

    // íŠ¸ëœì­ì…˜ ì²˜ë¦¬
    const { data: newRecord, error } = await supabase
      .from('education_records')
      .insert(mainData)
      .select()
      .single()

    if (error) throw error

    // ì»¤ë¦¬í˜ëŸ¼ ì¶”ê°€
    if (curriculum.length > 0) {
      await supabase
        .from('education_curriculum')
        .insert(curriculum.map(item => ({
          ...item,
          education_record_id: newRecord.id
        })))
    }

    // ì°¸ì„ì ì¶”ê°€
    if (participants.length > 0) {
      await supabase
        .from('education_participants')
        .insert(participants.map(item => ({
          ...item,
          education_record_id: newRecord.id
        })))
    }

    return newRecord
  }
}
```

## ğŸ” 4. ì¸ì¦ ë° ë³´ì•ˆ ì„¤ì •

### 4.1 Supabase Auth ì„¤ì •

```typescript
// contexts/AuthContext.tsx
'use client'

import { createContext, useContext, useEffect, useState } from 'react'
import { User, Session } from '@supabase/supabase-js'
import { supabase } from '@/lib/supabase'

interface AuthContextType {
  user: User | null
  session: Session | null
  loading: boolean
  signIn: (email: string, password: string) => Promise<void>
  signUp: (email: string, password: string, userData: any) => Promise<void>
  signOut: () => Promise<void>
}

const AuthContext = createContext<AuthContextType>({} as AuthContextType)

export function AuthProvider({ children }: { children: React.ReactNode }) {
  const [user, setUser] = useState<User | null>(null)
  const [session, setSession] = useState<Session | null>(null)
  const [loading, setLoading] = useState(true)

  useEffect(() => {
    // ì´ˆê¸° ì„¸ì…˜ í™•ì¸
    supabase.auth.getSession().then(({ data: { session } }) => {
      setSession(session)
      setUser(session?.user ?? null)
      setLoading(false)
    })

    // Auth ìƒíƒœ ë³€ê²½ ë¦¬ìŠ¤ë„ˆ
    const { data: { subscription } } = supabase.auth.onAuthStateChange(
      async (event, session) => {
        setSession(session)
        setUser(session?.user ?? null)
        setLoading(false)

        // í”„ë¡œí•„ ì •ë³´ ë™ê¸°í™”
        if (session?.user) {
          await syncUserProfile(session.user)
        }
      }
    )

    return () => subscription.unsubscribe()
  }, [])

  const signIn = async (email: string, password: string) => {
    const { error } = await supabase.auth.signInWithPassword({
      email,
      password
    })
    if (error) throw error
  }

  const signUp = async (email: string, password: string, userData: any) => {
    const { error } = await supabase.auth.signUp({
      email,
      password,
      options: {
        data: userData
      }
    })
    if (error) throw error
  }

  const signOut = async () => {
    const { error } = await supabase.auth.signOut()
    if (error) throw error
  }

  return (
    <AuthContext.Provider value={{
      user,
      session,
      loading,
      signIn,
      signUp,
      signOut
    }}>
      {children}
    </AuthContext.Provider>
  )
}

// ì‚¬ìš©ì í”„ë¡œí•„ ë™ê¸°í™”
async function syncUserProfile(user: User) {
  const { data: profile, error } = await supabase
    .from('user_profiles')
    .select('*')
    .eq('id', user.id)
    .single()

  if (error && error.code === 'PGRST116') {
    // í”„ë¡œí•„ì´ ì—†ìœ¼ë©´ ìƒì„±
    await supabase
      .from('user_profiles')
      .insert({
        id: user.id,
        email: user.email!,
        name: user.user_metadata?.name || '',
        avatar_url: user.user_metadata?.avatar_url
      })
  }
}

export const useAuth = () => {
  const context = useContext(AuthContext)
  if (!context) {
    throw new Error('useAuth must be used within an AuthProvider')
  }
  return context
}
```

### 4.2 Row Level Security (RLS) ì •ì±…

```sql
-- ì‚¬ìš©ì í”„ë¡œí•„ ì •ì±…
CREATE POLICY "Enable read access for authenticated users" ON user_profiles
  FOR SELECT USING (auth.role() = 'authenticated');

-- ë¹„ìš© ê¸°ë¡ ì •ì±…
CREATE POLICY "Enable read access for authenticated users" ON cost_records
  FOR SELECT USING (auth.role() = 'authenticated');

CREATE POLICY "Enable insert for authenticated users" ON cost_records
  FOR INSERT WITH CHECK (auth.role() = 'authenticated');

CREATE POLICY "Enable update for record owners and managers" ON cost_records
  FOR UPDATE USING (
    auth.uid() = created_by OR 
    EXISTS (
      SELECT 1 FROM user_profiles 
      WHERE id = auth.uid() AND role IN ('admin', 'manager')
    )
  );

-- ì²¨ë¶€íŒŒì¼ ì •ì±…
CREATE POLICY "Users can upload files to their records" ON cost_attachments
  FOR INSERT WITH CHECK (
    EXISTS (
      SELECT 1 FROM cost_records 
      WHERE id = cost_record_id AND 
      (created_by = auth.uid() OR assignee_id = auth.uid())
    )
  );
```

### 4.3 Edge Functions ì˜ˆì‹œ

```typescript
// supabase/functions/generate-report/index.ts
import { serve } from "https://deno.land/std@0.168.0/http/server.ts"
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2'

serve(async (req) => {
  try {
    const supabaseClient = createClient(
      Deno.env.get('SUPABASE_URL') ?? '',
      Deno.env.get('SUPABASE_ANON_KEY') ?? '',
      {
        global: { headers: { Authorization: req.headers.get('Authorization')! } }
      }
    )

    const { type, filters } = await req.json()

    switch (type) {
      case 'cost-report':
        const { data: costData } = await supabaseClient
          .from('cost_records')
          .select('*')
          .gte('registration_date', filters.startDate)
          .lte('registration_date', filters.endDate)

        // ë¦¬í¬íŠ¸ ìƒì„± ë¡œì§
        const report = generateCostReport(costData)
        
        return new Response(
          JSON.stringify({ report }),
          { headers: { "Content-Type": "application/json" } }
        )

      default:
        throw new Error('ì§€ì›ë˜ì§€ ì•ŠëŠ” ë¦¬í¬íŠ¸ íƒ€ì…')
    }
  } catch (error) {
    return new Response(
      JSON.stringify({ error: error.message }),
      { status: 400, headers: { "Content-Type": "application/json" } }
    )
  }
})
```

## ğŸ“± 5. Real-time ê¸°ëŠ¥ êµ¬í˜„

### 5.1 ì‹¤ì‹œê°„ ë°ì´í„° ë™ê¸°í™”

```typescript
// hooks/useRealtime.ts
import { useEffect, useState } from 'react'
import { supabase } from '@/lib/supabase'

export function useRealtimeCosts() {
  const [costs, setCosts] = useState<CostRecord[]>([])

  useEffect(() => {
    // ì´ˆê¸° ë°ì´í„° ë¡œë“œ
    loadCosts()

    // ì‹¤ì‹œê°„ êµ¬ë…
    const channel = supabase
      .channel('cost_changes')
      .on(
        'postgres_changes',
        {
          event: '*',
          schema: 'public',
          table: 'cost_records'
        },
        (payload) => {
          handleRealtimeUpdate(payload)
        }
      )
      .subscribe()

    return () => {
      supabase.removeChannel(channel)
    }
  }, [])

  const loadCosts = async () => {
    const { data } = await CostAPI.getCostRecords()
    setCosts(data || [])
  }

  const handleRealtimeUpdate = (payload: any) => {
    if (payload.eventType === 'INSERT') {
      setCosts(prev => [payload.new, ...prev])
    } else if (payload.eventType === 'UPDATE') {
      setCosts(prev => 
        prev.map(item => 
          item.id === payload.new.id ? payload.new : item
        )
      )
    } else if (payload.eventType === 'DELETE') {
      setCosts(prev => 
        prev.filter(item => item.id !== payload.old.id)
      )
    }
  }

  return costs
}
```

## ğŸ—‚ï¸ 6. Storage ì„¤ì •

### 6.1 íŒŒì¼ ì €ì¥ì†Œ êµ¬ì„±

```sql
-- Storage Bucket ìƒì„± (Supabase ëŒ€ì‹œë³´ë“œì—ì„œ)
INSERT INTO storage.buckets (id, name, public) VALUES 
('cost-attachments', 'cost-attachments', false),
('task-attachments', 'task-attachments', false),
('education-materials', 'education-materials', false),
('user-avatars', 'user-avatars', true);

-- Storage ì •ì±… ì„¤ì •
CREATE POLICY "Authenticated users can upload files" ON storage.objects
  FOR INSERT WITH CHECK (auth.role() = 'authenticated');

CREATE POLICY "Users can view files in their records" ON storage.objects
  FOR SELECT USING (
    auth.role() = 'authenticated' AND 
    bucket_id IN ('cost-attachments', 'task-attachments', 'education-materials')
  );

CREATE POLICY "Public avatar access" ON storage.objects
  FOR SELECT USING (bucket_id = 'user-avatars');
```

### 6.2 íŒŒì¼ ì—…ë¡œë“œ ì»´í¬ë„ŒíŠ¸

```typescript
// components/FileUpload.tsx
import { useState } from 'react'
import { supabase } from '@/lib/supabase'

interface FileUploadProps {
  bucket: string
  onUpload: (path: string, file: File) => void
  accept?: string
  maxSize?: number
}

export function FileUpload({ bucket, onUpload, accept, maxSize = 10 * 1024 * 1024 }: FileUploadProps) {
  const [uploading, setUploading] = useState(false)

  const handleUpload = async (event: React.ChangeEvent<HTMLInputElement>) => {
    const file = event.target.files?.[0]
    if (!file) return

    if (maxSize && file.size > maxSize) {
      alert('íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤.')
      return
    }

    try {
      setUploading(true)

      const fileExt = file.name.split('.').pop()
      const fileName = `${Date.now()}.${fileExt}`

      const { data, error } = await supabase.storage
        .from(bucket)
        .upload(fileName, file, {
          cacheControl: '3600',
          upsert: false
        })

      if (error) throw error

      onUpload(data.path, file)
    } catch (error) {
      console.error('íŒŒì¼ ì—…ë¡œë“œ ì‹¤íŒ¨:', error)
      alert('íŒŒì¼ ì—…ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.')
    } finally {
      setUploading(false)
    }
  }

  return (
    <div>
      <input
        type="file"
        accept={accept}
        onChange={handleUpload}
        disabled={uploading}
      />
      {uploading && <p>ì—…ë¡œë“œ ì¤‘...</p>}
    </div>
  )
}
```

## ğŸš€ Phase 1: ì‚¬ì „ ì¤€ë¹„ ì™„ì „ ê°€ì´ë“œ (100% ë‹¬ì„±)

### âœ… 1.1 íŒ€ êµìœ¡ ë° í™˜ê²½ ì¤€ë¹„ (ì¦‰ì‹œ ì‹¤í–‰)

#### ğŸ“š Supabase êµìœ¡ ìë£Œ ì¤€ë¹„
```bash
# 1. êµìœ¡ ìë£Œ í´ë” ìƒì„±
mkdir -p docs/supabase-guide

# 2. ê¸°ë³¸ ê°œë… ë¬¸ì„œ ìƒì„±
cat > docs/supabase-guide/01-basic-concepts.md << 'EOF'
# Supabase ê¸°ë³¸ ê°œë…

## 1. PostgreSQL ë°ì´í„°ë² ì´ìŠ¤
- ACID ì†ì„±ì„ ë³´ì¥í•˜ëŠ” ê´€ê³„í˜• ë°ì´í„°ë² ì´ìŠ¤
- ê°•ë ¥í•œ ì¿¼ë¦¬ ì„±ëŠ¥ê³¼ í™•ì¥ì„±

## 2. Row Level Security (RLS)
- í…Œì´ë¸” í–‰ ë‹¨ìœ„ ë³´ì•ˆ ì •ì±…
- ì‚¬ìš©ìë³„/ì—­í• ë³„ ë°ì´í„° ì ‘ê·¼ ì œì–´

## 3. Real-time êµ¬ë…
- WebSocket ê¸°ë°˜ ì‹¤ì‹œê°„ ë°ì´í„° ë™ê¸°í™”
- INSERT, UPDATE, DELETE ì´ë²¤íŠ¸ êµ¬ë… ê°€ëŠ¥

## 4. Storage
- íŒŒì¼ ì—…ë¡œë“œ/ë‹¤ìš´ë¡œë“œ ê´€ë¦¬
- ì´ë¯¸ì§€ ë³€í™˜ ë° ìµœì í™” ì§€ì›
EOF

# 3. PostgreSQL ì¿¼ë¦¬ ê°€ì´ë“œ ìƒì„±
cat > docs/supabase-guide/02-postgresql-queries.md << 'EOF'
# PostgreSQL ì¿¼ë¦¬ ì‘ì„± ê°€ì´ë“œ

## ê¸°ë³¸ ì¿¼ë¦¬ íŒ¨í„´
```sql
-- ë°ì´í„° ì¡°íšŒ (í•„í„°ë§ + ì •ë ¬)
SELECT * FROM cost_records 
WHERE status = 'ì§„í–‰' 
ORDER BY created_at DESC;

-- ì¡°ì¸ ì¿¼ë¦¬
SELECT cr.*, up.name as assignee_name
FROM cost_records cr
LEFT JOIN user_profiles up ON cr.assignee_id = up.id;

-- ì§‘ê³„ ì¿¼ë¦¬
SELECT status, COUNT(*) as count, SUM(amount) as total
FROM cost_records 
GROUP BY status;
```
EOF

# 4. RLS ì •ì±… ê°€ì´ë“œ ìƒì„±  
cat > docs/supabase-guide/03-rls-policies.md << 'EOF'
# Row Level Security ì •ì±… ì‘ì„± ê°€ì´ë“œ

## ê¸°ë³¸ íŒ¨í„´
```sql
-- 1. RLS í™œì„±í™”
ALTER TABLE table_name ENABLE ROW LEVEL SECURITY;

-- 2. ì½ê¸° ì •ì±…
CREATE POLICY "ì‚¬ìš©ìëŠ” ë³¸ì¸ ë°ì´í„°ë§Œ ì¡°íšŒ ê°€ëŠ¥" ON table_name
  FOR SELECT USING (user_id = auth.uid());

-- 3. ì“°ê¸° ì •ì±…  
CREATE POLICY "ì‚¬ìš©ìëŠ” ë³¸ì¸ ë°ì´í„°ë§Œ ìˆ˜ì • ê°€ëŠ¥" ON table_name
  FOR UPDATE USING (user_id = auth.uid());
```
EOF
```

#### ğŸ› ï¸ ê°œë°œ ë„êµ¬ ìë™ ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸
```bash
# setup-dev-environment.sh ìƒì„±
cat > setup-dev-environment.sh << 'EOF'
#!/bin/bash
set -e

echo "ğŸš€ Nexwork Supabase ê°œë°œ í™˜ê²½ ì„¤ì • ì‹œì‘..."

# 1. Supabase CLI ì„¤ì¹˜
echo "ğŸ“¦ Supabase CLI ì„¤ì¹˜ ì¤‘..."
npm install -g supabase

# 2. PostgreSQL í´ë¼ì´ì–¸íŠ¸ ì„¤ì¹˜ ì•ˆë‚´
echo "ğŸ”§ PostgreSQL í´ë¼ì´ì–¸íŠ¸ ì„¤ì¹˜ ì•ˆë‚´:"
echo "- Windows: https://www.pgadmin.org/download/pgadmin-4-windows/"
echo "- macOS: brew install --cask pgadmin4"
echo "- Ubuntu: sudo apt install pgadmin4-desktop"

# 3. Git hooks ì„¤ì •
echo "ğŸ”— Git hooks ì„¤ì • ì¤‘..."
mkdir -p .git/hooks

cat > .git/hooks/pre-commit << 'HOOK'
#!/bin/bash
# TypeScript íƒ€ì… ì²´í¬
npm run typecheck
# ESLint ê²€ì‚¬
npm run lint
HOOK

chmod +x .git/hooks/pre-commit

# 4. VSCode ì„¤ì • ì¶”ê°€
mkdir -p .vscode
cat > .vscode/extensions.json << 'VSCODE'
{
  "recommendations": [
    "bradlc.vscode-tailwindcss",
    "ms-vscode.vscode-typescript-next",
    "supabase.supabase-vscode",
    "ms-vscode.vscode-json"
  ]
}
VSCODE

echo "âœ… ê°œë°œ í™˜ê²½ ì„¤ì • ì™„ë£Œ!"
echo "ğŸ¯ ë‹¤ìŒ ë‹¨ê³„: Phase 2 - ì¸í”„ë¼ êµ¬ì¶•"
EOF

chmod +x setup-dev-environment.sh
./setup-dev-environment.sh
```

### âœ… 1.2 ì„±ëŠ¥ ìš”êµ¬ì‚¬í•­ ì •ëŸ‰í™” (ì™„ë£Œ ê²€ì¦ í¬í•¨)

#### ğŸ“Š ì„±ëŠ¥ ê¸°ì¤€ ëª…ì„¸ì„œ ìƒì„±
```bash
cat > docs/performance-requirements.md << 'EOF'
# ì„±ëŠ¥ ìš”êµ¬ì‚¬í•­ ëª…ì„¸ì„œ

## ğŸ¯ ëª©í‘œ ì„±ëŠ¥ ì§€í‘œ
| í•­ëª© | ëª©í‘œê°’ | ì¸¡ì • ë°©ë²• |
|------|--------|-----------|
| í˜ì´ì§€ ë¡œë”© ì‹œê°„ | < 2ì´ˆ | Lighthouse Performance |
| API ì‘ë‹µ ì‹œê°„ | < 500ms | Network íƒ­ ì¸¡ì • |
| DB ì¿¼ë¦¬ ì‹œê°„ | < 100ms | EXPLAIN ANALYZE |
| íŒŒì¼ ì—…ë¡œë“œ ì†ë„ | > 1MB/s | ì‹¤ì œ íŒŒì¼ ì—…ë¡œë“œ í…ŒìŠ¤íŠ¸ |

## ğŸ“ˆ ì˜ˆìƒ ì‚¬ìš©ëŸ‰
- **ë™ì‹œ ì‚¬ìš©ì**: 100ëª…
- **ì¼ì¼ í™œì„± ì‚¬ìš©ì**: 500ëª…  
- **DB í¬ê¸°**: 1GB (1ë…„ ìš´ì˜ ê¸°ì¤€)
- **ì›”ê°„ API ìš”ì²­**: 100ë§Œ ê±´
- **Storage ì‚¬ìš©ëŸ‰**: 10GB

## ğŸ” ì„±ëŠ¥ ì¸¡ì • ìŠ¤í¬ë¦½íŠ¸
```bash
# ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
npm run test:performance
```
EOF

# ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
cat > scripts/performance-test.js << 'EOF'
const lighthouse = require('lighthouse');
const chromeLauncher = require('chrome-launcher');

async function runPerformanceTest() {
  const chrome = await chromeLauncher.launch({chromeFlags: ['--headless']});
  const options = {logLevel: 'info', output: 'html', onlyCategories: ['performance'], port: chrome.port};
  const runnerResult = await lighthouse('http://localhost:3000', options);
  
  console.log('Performance Score:', runnerResult.lhr.categories.performance.score * 100);
  
  await chrome.kill();
}

runPerformanceTest();
EOF
```

---

## ğŸ—ï¸ Phase 2: ì¸í”„ë¼ êµ¬ì¶• ì™„ì „ ê°€ì´ë“œ (100% ë‹¬ì„±)

### âœ… 2.1 Supabase í”„ë¡œì íŠ¸ ìë™ ì„¤ì •

#### ğŸš€ ì™„ì „ ìë™í™” ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸
```bash
# create-supabase-project.sh ìƒì„±
cat > create-supabase-project.sh << 'EOF'
#!/bin/bash
set -e

echo "ğŸš€ Supabase í”„ë¡œì íŠ¸ ìƒì„± ê°€ì´ë“œ"
echo "================================="

# 1. Supabase ê³„ì • í™•ì¸
echo "1ï¸âƒ£ Supabase ê³„ì • ìƒì„± í™•ì¸"
echo "   - https://supabase.com/dashboard ë°©ë¬¸"
echo "   - GitHub ë˜ëŠ” ì´ë©”ì¼ë¡œ íšŒì›ê°€ì…"
echo "   - ê³„ì • ìƒì„± ì™„ë£Œí–ˆìŠµë‹ˆê¹Œ? (y/n)"
read -r account_created
if [[ $account_created != "y" ]]; then
  echo "âŒ ê³„ì •ì„ ë¨¼ì € ìƒì„±í•´ì£¼ì„¸ìš”"
  exit 1
fi

# 2. í”„ë¡œì íŠ¸ ìƒì„± ê°€ì´ë“œ
echo ""
echo "2ï¸âƒ£ ìƒˆ í”„ë¡œì íŠ¸ ìƒì„±"
echo "   - 'New project' í´ë¦­"
echo "   - Project name: nexwork-backend"
echo "   - Database password: [ê°•ë ¥í•œ ë¹„ë°€ë²ˆí˜¸ ìƒì„±]"
echo "   - Region: Asia Pacific (ap-northeast-1) ì„ íƒ"
echo "   - Pricing plan: Free tier ì„ íƒ"
echo ""
echo "í”„ë¡œì íŠ¸ ìƒì„±ì„ ì™„ë£Œí–ˆìŠµë‹ˆê¹Œ? (y/n)"
read -r project_created
if [[ $project_created != "y" ]]; then
  echo "âŒ í”„ë¡œì íŠ¸ë¥¼ ë¨¼ì € ìƒì„±í•´ì£¼ì„¸ìš”"
  exit 1
fi

# 3. API Keys ì •ë³´ ì…ë ¥
echo ""
echo "3ï¸âƒ£ API Keys ì„¤ì •"
echo "Dashboard > Settings > API í˜ì´ì§€ì—ì„œ ë‹¤ìŒ ì •ë³´ë¥¼ í™•ì¸í•˜ì„¸ìš”:"
echo ""
echo "Project URLì„ ì…ë ¥í•˜ì„¸ìš”:"
read -r project_url
echo "anon public keyë¥¼ ì…ë ¥í•˜ì„¸ìš”:"
read -r anon_key
echo "service_role keyë¥¼ ì…ë ¥í•˜ì„¸ìš”:"  
read -r service_key

# 4. í™˜ê²½ë³€ìˆ˜ íŒŒì¼ ìƒì„±
echo ""
echo "4ï¸âƒ£ í™˜ê²½ë³€ìˆ˜ ì„¤ì • ì¤‘..."
cat > .env.local << ENV
## Supabase Configuration
NEXT_PUBLIC_SUPABASE_URL=${project_url}
NEXT_PUBLIC_SUPABASE_ANON_KEY=${anon_key}
SUPABASE_SERVICE_ROLE_KEY=${service_key}

## Database URL (for migrations)
DATABASE_URL=${project_url/https:\/\//postgresql://postgres:[PASSWORD]@}/postgres?sslmode=require

## ê¸°ì¡´ ì„¤ì • ìœ ì§€
NEXT_PUBLIC_VERSION=v3.0.0
GENERATE_SOURCEMAP=false
NEXT_PUBLIC_API_URL=https://mock-data-api-nextjs.vercel.app/
NEXT_PUBLIC_GOOGLE_MAPS_API_KEY=AIzaSyAXv4RQK39CskcIB8fvM1Q7XCofZcLxUXw
NEXT_PUBLIC_MAPBOX_ACCESS_TOKEN=pk.eyJ1IjoicmFrZXNoLW5ha3JhbmkiLCJhIjoiY2xsNjNkZm0yMGhvcDNlb3phdjF4dHlzeiJ9.ps6azYbr7M3rGk_QTguMEQ
NEXTAUTH_URL=http://localhost:3200
NEXTAUTH_SECRET=LlKq6ZtYbr+hTC073mAmAh9/h2HwMfsFo4hrfCx5mLg=
NEXT_APP_JWT_TIMEOUT=86400
JWT_SECRET=ikRgjkhi15HJiU78-OLKfjngiu
ENV

# 5. Supabase íŒ¨í‚¤ì§€ ì„¤ì¹˜
echo ""
echo "5ï¸âƒ£ Supabase íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì¤‘..."
npm install @supabase/supabase-js
npm install -D supabase

# 6. Supabase ì´ˆê¸°í™”
echo ""
echo "6ï¸âƒ£ Supabase ë¡œì»¬ í™˜ê²½ ì´ˆê¸°í™” ì¤‘..."
npx supabase init

# 7. ì„¤ì • ì™„ë£Œ í™•ì¸
echo ""
echo "âœ… Supabase ì¸í”„ë¼ ì„¤ì • ì™„ë£Œ!"
echo ""
echo "ğŸ“‹ ë‹¤ìŒ ë‹¨ê³„:"
echo "   1. npx supabase start (ë¡œì»¬ í™˜ê²½ ì‹œì‘)"
echo "   2. Database ìŠ¤í‚¤ë§ˆ ìƒì„±"
echo "   3. ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜"
echo ""
echo "ğŸ”— ìœ ìš©í•œ ë§í¬:"
echo "   - Supabase Dashboard: ${project_url}"
echo "   - ë¡œì»¬ Studio: http://localhost:54323"
EOF

chmod +x create-supabase-project.sh
```

#### ğŸ”§ ë¡œì»¬ ê°œë°œ í™˜ê²½ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸
```bash
# verify-local-setup.sh ìƒì„±
cat > verify-local-setup.sh << 'EOF'
#!/bin/bash
set -e

echo "ğŸ” Supabase ë¡œì»¬ í™˜ê²½ ê²€ì¦ ì¤‘..."

# 1. Docker ì‹¤í–‰ ìƒíƒœ í™•ì¸
if ! docker info > /dev/null 2>&1; then
    echo "âŒ Dockerê°€ ì‹¤í–‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Docker Desktopì„ ì‹œì‘í•´ì£¼ì„¸ìš”."
    exit 1
fi
echo "âœ… Docker ì‹¤í–‰ í™•ì¸"

# 2. Supabase CLI ì„¤ì¹˜ í™•ì¸
if ! command -v supabase &> /dev/null; then
    echo "âŒ Supabase CLIê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    exit 1
fi
echo "âœ… Supabase CLI ì„¤ì¹˜ í™•ì¸"

# 3. í™˜ê²½ë³€ìˆ˜ íŒŒì¼ í™•ì¸
if [ ! -f .env.local ]; then
    echo "âŒ .env.local íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤."
    exit 1
fi
echo "âœ… í™˜ê²½ë³€ìˆ˜ íŒŒì¼ í™•ì¸"

# 4. Supabase ë¡œì»¬ ì„œë¹„ìŠ¤ ì‹œì‘
echo "ğŸš€ Supabase ë¡œì»¬ ì„œë¹„ìŠ¤ ì‹œì‘ ì¤‘..."
supabase start

# 5. ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
sleep 10
if curl -f http://localhost:54323 > /dev/null 2>&1; then
    echo "âœ… Supabase Studio ì ‘ê·¼ ê°€ëŠ¥ (http://localhost:54323)"
else
    echo "âŒ Supabase Studio ì ‘ê·¼ ë¶ˆê°€"
    exit 1
fi

if curl -f http://localhost:54321/health > /dev/null 2>&1; then
    echo "âœ… Supabase API ì •ìƒ ì‘ë™"
else
    echo "âŒ Supabase API ì ‘ê·¼ ë¶ˆê°€"
    exit 1
fi

echo ""
echo "ğŸ‰ ë¡œì»¬ í™˜ê²½ ì„¤ì • ì™„ë£Œ!"
echo "ğŸ“‹ ì ‘ê·¼ ì •ë³´:"
echo "   - Studio UI: http://localhost:54323"
echo "   - API URL: http://localhost:54321"  
echo "   - DB URL: postgresql://postgres:postgres@localhost:54322/postgres"
EOF

chmod +x verify-local-setup.sh
```

---

## ğŸ—„ï¸ Phase 3: ë°ì´í„°ë² ì´ìŠ¤ ì™„ì „ êµ¬í˜„ ê°€ì´ë“œ (100% ë‹¬ì„±)

### âœ… 3.1 ì‹¤í–‰ ê°€ëŠ¥í•œ ìŠ¤í‚¤ë§ˆ ìƒì„±

#### ğŸ“‹ ì™„ì „í•œ ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸
```bash
# ë§ˆì´ê·¸ë ˆì´ì…˜ íŒŒì¼ ìƒì„±
supabase migration new "01_create_initial_schema"

# SQL ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±
cat > supabase/migrations/$(ls supabase/migrations/ | grep "01_create_initial_schema").sql << 'EOF'
-- =========================================
-- 1. Extensions and Functions
-- =========================================

-- UUID í™•ì¥ í™œì„±í™”
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";

-- Updated at íŠ¸ë¦¬ê±° í•¨ìˆ˜
CREATE OR REPLACE FUNCTION update_updated_at_column()
RETURNS TRIGGER AS $$
BEGIN
    NEW.updated_at = CURRENT_TIMESTAMP;
    RETURN NEW;
END;
$$ language 'plpgsql';

-- ì½”ë“œ ìƒì„± ì‹œí€€ìŠ¤ í•¨ìˆ˜
CREATE OR REPLACE FUNCTION get_next_sequence(p_module_type TEXT, p_year INTEGER)
RETURNS INTEGER AS $$
DECLARE
    v_current_sequence INTEGER;
BEGIN
    INSERT INTO code_sequences (module_type, current_year, current_sequence)
    VALUES (p_module_type, p_year, 1)
    ON CONFLICT (module_type) 
    DO UPDATE SET 
        current_sequence = CASE 
            WHEN code_sequences.current_year = p_year THEN code_sequences.current_sequence + 1
            ELSE 1
        END,
        current_year = p_year,
        updated_at = NOW();
    
    SELECT current_sequence INTO v_current_sequence 
    FROM code_sequences 
    WHERE module_type = p_module_type;
    
    RETURN v_current_sequence;
END;
$$ language 'plpgsql';

-- =========================================
-- 2. ì‚¬ìš©ì í”„ë¡œí•„ í…Œì´ë¸”
-- =========================================

CREATE TABLE user_profiles (
    id UUID REFERENCES auth.users(id) ON DELETE CASCADE PRIMARY KEY,
    email TEXT UNIQUE NOT NULL,
    name TEXT NOT NULL,
    avatar_url TEXT,
    role TEXT DEFAULT 'user' CHECK (role IN ('admin', 'manager', 'user')),
    department TEXT,
    position TEXT,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- RLS ì •ì±…
ALTER TABLE user_profiles ENABLE ROW LEVEL SECURITY;

CREATE POLICY "Public profiles are viewable by authenticated users" 
ON user_profiles FOR SELECT 
USING (auth.role() = 'authenticated');

CREATE POLICY "Users can insert their own profile" 
ON user_profiles FOR INSERT 
WITH CHECK (auth.uid() = id);

CREATE POLICY "Users can update their own profile" 
ON user_profiles FOR UPDATE 
USING (auth.uid() = id);

-- Updated at íŠ¸ë¦¬ê±°
CREATE TRIGGER update_user_profiles_updated_at 
    BEFORE UPDATE ON user_profiles 
    FOR EACH ROW 
    EXECUTE FUNCTION update_updated_at_column();

-- =========================================
-- 3. ì½”ë“œ ì‹œí€€ìŠ¤ ê´€ë¦¬ í…Œì´ë¸”
-- =========================================

CREATE TABLE code_sequences (
    module_type TEXT PRIMARY KEY,
    current_year INTEGER NOT NULL,
    current_sequence INTEGER NOT NULL DEFAULT 0,
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- =========================================
-- 4. ë¹„ìš©ê´€ë¦¬ í…Œì´ë¸”ë“¤
-- =========================================

-- ë¹„ìš© ê¸°ë¡ ë©”ì¸ í…Œì´ë¸”
CREATE TABLE cost_records (
    id UUID DEFAULT uuid_generate_v4() PRIMARY KEY,
    registration_date DATE NOT NULL,
    start_date DATE NOT NULL,
    code TEXT UNIQUE NOT NULL,
    team TEXT NOT NULL,
    assignee_id UUID REFERENCES user_profiles(id),
    cost_type TEXT NOT NULL CHECK (cost_type IN ('ì†”ë£¨ì…˜', 'í•˜ë“œì›¨ì–´', 'ì¶œì¥ê²½ë¹„', 'í–‰ì‚¬ê²½ë¹„', 'ì‚¬ë¬´ê²½ë¹„')),
    content TEXT NOT NULL,
    quantity INTEGER NOT NULL DEFAULT 1,
    unit_price DECIMAL(15,2) NOT NULL,
    amount DECIMAL(15,2) NOT NULL,
    status TEXT DEFAULT 'ëŒ€ê¸°' CHECK (status IN ('ëŒ€ê¸°', 'ì§„í–‰', 'ì™„ë£Œ', 'ì·¨ì†Œ')),
    completion_date DATE,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    created_by UUID REFERENCES user_profiles(id)
);

-- ê¸ˆì•¡ ê³„ì‚° ê²€ì¦ ì œì•½ì¡°ê±´
ALTER TABLE cost_records ADD CONSTRAINT check_amount_calculation 
CHECK (amount = quantity * unit_price);

-- ì¸ë±ìŠ¤ ìƒì„±
CREATE INDEX idx_cost_records_assignee ON cost_records(assignee_id);
CREATE INDEX idx_cost_records_status ON cost_records(status);
CREATE INDEX idx_cost_records_team ON cost_records(team);
CREATE INDEX idx_cost_records_date ON cost_records(registration_date DESC);
CREATE INDEX idx_cost_records_compound ON cost_records(status, team, registration_date DESC);

-- RLS ì •ì±…
ALTER TABLE cost_records ENABLE ROW LEVEL SECURITY;

CREATE POLICY "Authenticated users can view cost records" 
ON cost_records FOR SELECT 
USING (auth.role() = 'authenticated');

CREATE POLICY "Users can create cost records" 
ON cost_records FOR INSERT 
WITH CHECK (auth.role() = 'authenticated');

CREATE POLICY "Users can update their own cost records" 
ON cost_records FOR UPDATE 
USING (created_by = auth.uid() OR assignee_id = auth.uid());

-- Updated at íŠ¸ë¦¬ê±°
CREATE TRIGGER update_cost_records_updated_at 
    BEFORE UPDATE ON cost_records 
    FOR EACH ROW 
    EXECUTE FUNCTION update_updated_at_column();

-- ê¸ˆì•¡ ìƒì„¸ í…Œì´ë¸”
CREATE TABLE cost_amount_details (
    id UUID DEFAULT uuid_generate_v4() PRIMARY KEY,
    cost_record_id UUID REFERENCES cost_records(id) ON DELETE CASCADE,
    code TEXT NOT NULL,
    cost_type TEXT NOT NULL,
    content TEXT NOT NULL,
    quantity INTEGER NOT NULL,
    unit_price DECIMAL(15,2) NOT NULL,
    amount DECIMAL(15,2) NOT NULL
);

-- ë¹„ìš© ëŒ“ê¸€ í…Œì´ë¸”
CREATE TABLE cost_comments (
    id UUID DEFAULT uuid_generate_v4() PRIMARY KEY,
    cost_record_id UUID REFERENCES cost_records(id) ON DELETE CASCADE,
    author_id UUID REFERENCES user_profiles(id),
    content TEXT NOT NULL,
    timestamp TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- ë¹„ìš© ì²¨ë¶€íŒŒì¼ í…Œì´ë¸”
CREATE TABLE cost_attachments (
    id UUID DEFAULT uuid_generate_v4() PRIMARY KEY,
    cost_record_id UUID REFERENCES cost_records(id) ON DELETE CASCADE,
    name TEXT NOT NULL,
    file_type TEXT NOT NULL,
    file_size BIGINT NOT NULL,
    storage_path TEXT NOT NULL,
    upload_date TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    uploaded_by UUID REFERENCES user_profiles(id)
);

-- =========================================
-- 5. ì—…ë¬´ê´€ë¦¬ í…Œì´ë¸”ë“¤
-- =========================================

CREATE TABLE task_records (
    id UUID DEFAULT uuid_generate_v4() PRIMARY KEY,
    no SERIAL,
    registration_date DATE NOT NULL,
    code TEXT UNIQUE NOT NULL,
    team TEXT NOT NULL CHECK (team IN ('ê°œë°œíŒ€', 'ë””ìì¸íŒ€', 'ê¸°íšíŒ€', 'ë§ˆì¼€íŒ…íŒ€')),
    department TEXT NOT NULL CHECK (department IN ('IT', 'ê¸°íš')),
    work_content TEXT NOT NULL,
    status TEXT DEFAULT 'ëŒ€ê¸°' CHECK (status IN ('ëŒ€ê¸°', 'ì§„í–‰', 'ì™„ë£Œ', 'í™€ë”©')),
    assignee_id UUID REFERENCES user_profiles(id),
    start_date DATE,
    completed_date DATE,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    created_by UUID REFERENCES user_profiles(id)
);

-- ì¸ë±ìŠ¤ ìƒì„±
CREATE INDEX idx_task_records_assignee_status ON task_records(assignee_id, status) WHERE status != 'ì™„ë£Œ';
CREATE INDEX idx_task_records_team ON task_records(team);

-- RLS ì •ì±…
ALTER TABLE task_records ENABLE ROW LEVEL SECURITY;

CREATE POLICY "Authenticated users can view task records" 
ON task_records FOR SELECT 
USING (auth.role() = 'authenticated');

-- Updated at íŠ¸ë¦¬ê±°
CREATE TRIGGER update_task_records_updated_at 
    BEFORE UPDATE ON task_records 
    FOR EACH ROW 
    EXECUTE FUNCTION update_updated_at_column();

-- ì—…ë¬´ ì²¨ë¶€íŒŒì¼ í…Œì´ë¸”
CREATE TABLE task_attachments (
    id UUID DEFAULT uuid_generate_v4() PRIMARY KEY,
    task_record_id UUID REFERENCES task_records(id) ON DELETE CASCADE,
    filename TEXT NOT NULL,
    storage_path TEXT NOT NULL,
    upload_date TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- =========================================
-- 6. êµìœ¡ê´€ë¦¬ í…Œì´ë¸”ë“¤
-- =========================================

CREATE TABLE education_records (
    id UUID DEFAULT uuid_generate_v4() PRIMARY KEY,
    registration_date DATE NOT NULL,
    start_date DATE NOT NULL,
    code TEXT UNIQUE NOT NULL,
    education_type TEXT NOT NULL CHECK (education_type IN ('ì‹ ì…êµìœ¡', 'ë‹´ë‹¹ìêµìœ¡', 'ê´€ë¦¬ìêµìœ¡', 'ìˆ˜ì‹œêµìœ¡')),
    content TEXT NOT NULL,
    participants INTEGER DEFAULT 0,
    location TEXT NOT NULL,
    status TEXT DEFAULT 'ì˜ˆì •' CHECK (status IN ('ì˜ˆì •', 'ì§„í–‰', 'ì™„ë£Œ', 'ì·¨ì†Œ')),
    completion_date DATE,
    assignee_id UUID REFERENCES user_profiles(id),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    created_by UUID REFERENCES user_profiles(id)
);

-- ì¸ë±ìŠ¤ ìƒì„±
CREATE INDEX idx_education_records_status ON education_records(status);
CREATE INDEX idx_education_records_type ON education_records(education_type);

-- RLS ì •ì±…
ALTER TABLE education_records ENABLE ROW LEVEL SECURITY;

CREATE POLICY "Authenticated users can view education records" 
ON education_records FOR SELECT 
USING (auth.role() = 'authenticated');

-- Updated at íŠ¸ë¦¬ê±°
CREATE TRIGGER update_education_records_updated_at 
    BEFORE UPDATE ON education_records 
    FOR EACH ROW 
    EXECUTE FUNCTION update_updated_at_column();

-- êµìœ¡ ì»¤ë¦¬í˜ëŸ¼ í…Œì´ë¸”
CREATE TABLE education_curriculum (
    id UUID DEFAULT uuid_generate_v4() PRIMARY KEY,
    education_record_id UUID REFERENCES education_records(id) ON DELETE CASCADE,
    time_slot TEXT NOT NULL,
    subject TEXT NOT NULL,
    instructor TEXT NOT NULL,
    content TEXT NOT NULL,
    attachment_path TEXT,
    sort_order INTEGER DEFAULT 0
);

-- êµìœ¡ ì°¸ì„ì í…Œì´ë¸”
CREATE TABLE education_participants (
    id UUID DEFAULT uuid_generate_v4() PRIMARY KEY,
    education_record_id UUID REFERENCES education_records(id) ON DELETE CASCADE,
    participant_name TEXT NOT NULL,
    department TEXT NOT NULL,
    position TEXT NOT NULL,
    attendance TEXT DEFAULT 'ì˜ˆì •' CHECK (attendance IN ('ì˜ˆì •', 'ì°¸ì„', 'ë¶ˆì°¸')),
    report_path TEXT,
    note TEXT
);

-- êµìœ¡ ì‹¤ì  í…Œì´ë¸”
CREATE TABLE education_results (
    id UUID DEFAULT uuid_generate_v4() PRIMARY KEY,
    education_record_id UUID REFERENCES education_records(id) ON DELETE CASCADE,
    performance TEXT,
    improvement TEXT,
    feedback TEXT
);

-- =========================================
-- 7. ì‹œìŠ¤í…œ í…Œì´ë¸”ë“¤
-- =========================================

-- ì‹œìŠ¤í…œ ì„¤ì • í…Œì´ë¸”
CREATE TABLE system_settings (
    key TEXT PRIMARY KEY,
    value JSONB NOT NULL,
    description TEXT,
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_by UUID REFERENCES user_profiles(id)
);

-- í™œë™ ë¡œê·¸ í…Œì´ë¸” (ê°ì‚¬ ì¶”ì ìš©)
CREATE TABLE activity_logs (
    id UUID DEFAULT uuid_generate_v4() PRIMARY KEY,
    user_id UUID REFERENCES user_profiles(id),
    action TEXT NOT NULL,
    table_name TEXT NOT NULL,
    record_id UUID,
    old_values JSONB,
    new_values JSONB,
    timestamp TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    ip_address INET
);

-- ì„±ëŠ¥ ë¡œê·¸ í…Œì´ë¸”
CREATE TABLE performance_logs (
    id UUID DEFAULT uuid_generate_v4() PRIMARY KEY,
    query_name TEXT NOT NULL,
    duration_ms INTEGER NOT NULL,
    timestamp TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- =========================================
-- 8. ì´ˆê¸° ë°ì´í„° ì‚½ì…
-- =========================================

-- ì½”ë“œ ì‹œí€€ìŠ¤ ì´ˆê¸°í™”
INSERT INTO code_sequences (module_type, current_year, current_sequence) VALUES 
('COST', EXTRACT(YEAR FROM NOW()), 0),
('TASK', EXTRACT(YEAR FROM NOW()), 0),
('EDU', EXTRACT(YEAR FROM NOW()), 0);

-- ì‹œìŠ¤í…œ ì„¤ì • ì´ˆê¸°ê°’
INSERT INTO system_settings (key, value, description) VALUES 
('app_name', '"Nexwork Management System"', 'ì• í”Œë¦¬ì¼€ì´ì…˜ ì´ë¦„'),
('version', '"1.0.0"', 'í˜„ì¬ ë²„ì „'),
('maintenance_mode', 'false', 'ìœ ì§€ë³´ìˆ˜ ëª¨ë“œ'),
('max_file_size_mb', '10', 'ìµœëŒ€ íŒŒì¼ í¬ê¸° (MB)'),
('allowed_file_types', '["jpg", "jpeg", "png", "pdf", "docx", "xlsx", "pptx"]', 'í—ˆìš©ëœ íŒŒì¼ í˜•ì‹');
EOF

echo "âœ… ë§ˆì´ê·¸ë ˆì´ì…˜ íŒŒì¼ ìƒì„± ì™„ë£Œ!"
```

#### ğŸ” ìŠ¤í‚¤ë§ˆ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸
```bash
# validate-schema.sh ìƒì„±
cat > validate-schema.sh << 'EOF'
#!/bin/bash
set -e

echo "ğŸ” ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ê²€ì¦ ì¤‘..."

# 1. ë§ˆì´ê·¸ë ˆì´ì…˜ ì ìš©
echo "ğŸ“‹ ë§ˆì´ê·¸ë ˆì´ì…˜ ì ìš© ì¤‘..."
supabase db reset

# 2. í…Œì´ë¸” ì¡´ì¬ í™•ì¸
echo "ğŸ” í…Œì´ë¸” ì¡´ì¬ í™•ì¸ ì¤‘..."
TABLES="user_profiles cost_records task_records education_records"
for table in $TABLES; do
    if supabase db psql -c "\dt $table" | grep -q "$table"; then
        echo "âœ… $table í…Œì´ë¸” ì¡´ì¬ í™•ì¸"
    else
        echo "âŒ $table í…Œì´ë¸” ì—†ìŒ"
        exit 1
    fi
done

# 3. ì œì•½ì¡°ê±´ í™•ì¸
echo "ğŸ” ì œì•½ì¡°ê±´ í™•ì¸ ì¤‘..."
supabase db psql -c "
SELECT 
    tc.constraint_name, 
    tc.table_name, 
    kcu.column_name,
    tc.constraint_type
FROM information_schema.table_constraints tc
JOIN information_schema.key_column_usage kcu 
    ON tc.constraint_name = kcu.constraint_name
WHERE tc.table_schema = 'public'
    AND tc.constraint_type IN ('CHECK', 'FOREIGN KEY', 'UNIQUE')
ORDER BY tc.table_name;
"

# 4. ì¸ë±ìŠ¤ í™•ì¸
echo "ğŸ” ì¸ë±ìŠ¤ í™•ì¸ ì¤‘..."
supabase db psql -c "
SELECT indexname, tablename 
FROM pg_indexes 
WHERE schemaname = 'public' 
    AND indexname LIKE 'idx_%'
ORDER BY tablename;
"

# 5. RLS ì •ì±… í™•ì¸
echo "ğŸ” RLS ì •ì±… í™•ì¸ ì¤‘..."
supabase db psql -c "
SELECT schemaname, tablename, rowsecurity 
FROM pg_tables 
WHERE schemaname = 'public' 
    AND rowsecurity = true;
"

# 6. íŠ¸ë¦¬ê±° í™•ì¸
echo "ğŸ” íŠ¸ë¦¬ê±° í™•ì¸ ì¤‘..."
supabase db psql -c "
SELECT trigger_name, event_object_table 
FROM information_schema.triggers 
WHERE trigger_schema = 'public';
"

echo ""
echo "âœ… ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ê²€ì¦ ì™„ë£Œ!"
echo "ğŸ¯ ë‹¤ìŒ ë‹¨ê³„: Phase 4 - ë³´ì•ˆ ë° ê¶Œí•œ ê´€ë¦¬"
EOF

chmod +x validate-schema.sh
```

---

## ğŸ” Phase 4: ë³´ì•ˆ ë° ê¶Œí•œ ê´€ë¦¬ ì™„ì „ ê°€ì´ë“œ (100% ë‹¬ì„±)

### âœ… 4.1 Supabase Auth ì™„ì „ ì„¤ì •

#### ğŸ”‘ ì¸ì¦ ì‹œìŠ¤í…œ ìë™ ì„¤ì • ìŠ¤í¬ë¦½íŠ¸
```bash
# setup-authentication.sh ìƒì„±
cat > setup-authentication.sh << 'EOF'
#!/bin/bash
set -e

echo "ğŸ” Supabase Authentication ì„¤ì • ì‹œì‘..."

# 1. Supabase í´ë¼ì´ì–¸íŠ¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ìƒì„±
mkdir -p lib
cat > lib/supabase.ts << 'CLIENT'
import { createClient } from '@supabase/supabase-js'
import { Database } from '@/types/database.types'

const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL!
const supabaseAnonKey = process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!

export const supabase = createClient<Database>(supabaseUrl, supabaseAnonKey, {
  auth: {
    autoRefreshToken: true,
    persistSession: true,
    detectSessionInUrl: true,
    flowType: 'pkce'
  },
  realtime: {
    params: {
      eventsPerSecond: 10
    }
  }
})

// ì„œë²„ì‚¬ì´ë“œ í´ë¼ì´ì–¸íŠ¸ (Service Role Key ì‚¬ìš©)
export const supabaseAdmin = createClient<Database>(
  supabaseUrl,
  process.env.SUPABASE_SERVICE_ROLE_KEY!,
  {
    auth: {
      autoRefreshToken: false,
      persistSession: false
    }
  }
)
CLIENT

# 2. ì¸ì¦ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
mkdir -p contexts
cat > contexts/AuthContext.tsx << 'CONTEXT'
'use client'

import { createContext, useContext, useEffect, useState } from 'react'
import { User, Session, AuthError } from '@supabase/supabase-js'
import { supabase } from '@/lib/supabase'

interface UserProfile {
  id: string
  email: string
  name: string
  avatar_url?: string
  role: 'admin' | 'manager' | 'user'
  department?: string
  position?: string
}

interface AuthContextType {
  user: User | null
  profile: UserProfile | null
  session: Session | null
  loading: boolean
  signIn: (email: string, password: string) => Promise<{ error?: AuthError }>
  signUp: (email: string, password: string, userData: Partial<UserProfile>) => Promise<{ error?: AuthError }>
  signOut: () => Promise<{ error?: AuthError }>
  updateProfile: (updates: Partial<UserProfile>) => Promise<{ error?: Error }>
}

const AuthContext = createContext<AuthContextType>({} as AuthContextType)

export function AuthProvider({ children }: { children: React.ReactNode }) {
  const [user, setUser] = useState<User | null>(null)
  const [profile, setProfile] = useState<UserProfile | null>(null)
  const [session, setSession] = useState<Session | null>(null)
  const [loading, setLoading] = useState(true)

  useEffect(() => {
    // ì´ˆê¸° ì„¸ì…˜ í™•ì¸
    supabase.auth.getSession().then(({ data: { session } }) => {
      setSession(session)
      setUser(session?.user ?? null)
      if (session?.user) {
        loadUserProfile(session.user.id)
      }
      setLoading(false)
    })

    // Auth ìƒíƒœ ë³€ê²½ ë¦¬ìŠ¤ë„ˆ
    const { data: { subscription } } = supabase.auth.onAuthStateChange(
      async (event, session) => {
        console.log('Auth event:', event)
        setSession(session)
        setUser(session?.user ?? null)

        if (session?.user) {
          await loadUserProfile(session.user.id)
        } else {
          setProfile(null)
        }
        setLoading(false)
      }
    )

    return () => subscription.unsubscribe()
  }, [])

  const loadUserProfile = async (userId: string) => {
    try {
      const { data: profile, error } = await supabase
        .from('user_profiles')
        .select('*')
        .eq('id', userId)
        .single()

      if (error && error.code === 'PGRST116') {
        // í”„ë¡œí•„ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ í”„ë¡œí•„ ìƒì„±
        const defaultProfile = {
          id: userId,
          email: user?.email || '',
          name: user?.user_metadata?.name || user?.email?.split('@')[0] || '',
          role: 'user' as const
        }
        
        const { data: newProfile, error: insertError } = await supabase
          .from('user_profiles')
          .insert(defaultProfile)
          .select()
          .single()

        if (!insertError) {
          setProfile(newProfile)
        }
      } else if (!error) {
        setProfile(profile)
      }
    } catch (error) {
      console.error('Error loading user profile:', error)
    }
  }

  const signIn = async (email: string, password: string) => {
    const result = await supabase.auth.signInWithPassword({
      email,
      password
    })
    return { error: result.error }
  }

  const signUp = async (email: string, password: string, userData: Partial<UserProfile>) => {
    const result = await supabase.auth.signUp({
      email,
      password,
      options: {
        data: {
          name: userData.name || email.split('@')[0]
        }
      }
    })

    // íšŒì›ê°€ì… ì„±ê³µ ì‹œ í”„ë¡œí•„ ìƒì„±
    if (result.data.user && !result.error) {
      await supabase.from('user_profiles').insert({
        id: result.data.user.id,
        email,
        name: userData.name || email.split('@')[0],
        role: userData.role || 'user',
        department: userData.department,
        position: userData.position
      })
    }

    return { error: result.error }
  }

  const signOut = async () => {
    const result = await supabase.auth.signOut()
    setProfile(null)
    return { error: result.error }
  }

  const updateProfile = async (updates: Partial<UserProfile>) => {
    if (!user) return { error: new Error('ì‚¬ìš©ìê°€ ì¸ì¦ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤') }

    try {
      const { error } = await supabase
        .from('user_profiles')
        .update(updates)
        .eq('id', user.id)

      if (!error && profile) {
        setProfile({ ...profile, ...updates })
      }

      return { error }
    } catch (error) {
      return { error: error as Error }
    }
  }

  const value = {
    user,
    profile,
    session,
    loading,
    signIn,
    signUp,
    signOut,
    updateProfile
  }

  return <AuthContext.Provider value={value}>{children}</AuthContext.Provider>
}

export const useAuth = () => {
  const context = useContext(AuthContext)
  if (!context) {
    throw new Error('useAuth must be used within an AuthProvider')
  }
  return context
}
CONTEXT

# 3. ë³´í˜¸ëœ ë¼ìš°íŠ¸ ì»´í¬ë„ŒíŠ¸
cat > contexts/ProtectedRoute.tsx << 'PROTECTED'
'use client'

import { useAuth } from './AuthContext'
import { useRouter } from 'next/navigation'
import { useEffect } from 'react'

interface ProtectedRouteProps {
  children: React.ReactNode
  requiredRole?: 'admin' | 'manager' | 'user'
  fallback?: React.ReactNode
}

export function ProtectedRoute({ 
  children, 
  requiredRole = 'user', 
  fallback = <div>ì ‘ê·¼ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤.</div> 
}: ProtectedRouteProps) {
  const { user, profile, loading } = useAuth()
  const router = useRouter()

  useEffect(() => {
    if (!loading && !user) {
      router.push('/login')
    }
  }, [user, loading, router])

  if (loading) {
    return <div>ë¡œë”© ì¤‘...</div>
  }

  if (!user || !profile) {
    return null
  }

  // ì—­í•  ê¸°ë°˜ ì ‘ê·¼ ì œì–´
  const roleHierarchy = { admin: 3, manager: 2, user: 1 }
  const userLevel = roleHierarchy[profile.role]
  const requiredLevel = roleHierarchy[requiredRole]

  if (userLevel < requiredLevel) {
    return fallback
  }

  return <>{children}</>
}
PROTECTED

echo "âœ… ì¸ì¦ ì‹œìŠ¤í…œ ì„¤ì • ì™„ë£Œ!"
EOF

chmod +x setup-authentication.sh
./setup-authentication.sh
```

#### ğŸ”’ RLS ì •ì±… í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
```bash
# test-rls-policies.sh ìƒì„±
cat > test-rls-policies.sh << 'EOF'
#!/bin/bash
set -e

echo "ğŸ” RLS ì •ì±… í…ŒìŠ¤íŠ¸ ì‹œì‘..."

# í…ŒìŠ¤íŠ¸ìš© ì‚¬ìš©ì ìƒì„± í•¨ìˆ˜
create_test_user() {
    local email=$1
    local role=$2
    
    # Supabase Auth APIë¥¼ í†µí•´ ì‚¬ìš©ì ìƒì„±
    supabase db psql -c "
    INSERT INTO auth.users (
        instance_id,
        id,
        aud,
        role,
        email,
        encrypted_password,
        email_confirmed_at,
        created_at,
        updated_at,
        confirmation_token,
        email_change,
        email_change_token,
        recovery_token
    ) VALUES (
        '00000000-0000-0000-0000-000000000000',
        gen_random_uuid(),
        'authenticated',
        'authenticated',
        '$email',
        crypt('password123', gen_salt('bf')),
        NOW(),
        NOW(),
        NOW(),
        '',
        '',
        '',
        ''
    );
    "
}

# 1. í…ŒìŠ¤íŠ¸ ì‚¬ìš©ìë“¤ ìƒì„±
echo "ğŸ“‹ í…ŒìŠ¤íŠ¸ ì‚¬ìš©ì ìƒì„± ì¤‘..."
create_test_user "admin@test.com" "admin"
create_test_user "manager@test.com" "manager"
create_test_user "user@test.com" "user"

# 2. ì‚¬ìš©ì í”„ë¡œí•„ ìƒì„±
echo "ğŸ‘¤ ì‚¬ìš©ì í”„ë¡œí•„ ìƒì„± ì¤‘..."
supabase db psql -c "
INSERT INTO user_profiles (id, email, name, role, department)
SELECT 
    id,
    email,
    SPLIT_PART(email, '@', 1),
    CASE 
        WHEN email = 'admin@test.com' THEN 'admin'
        WHEN email = 'manager@test.com' THEN 'manager'
        ELSE 'user'
    END,
    'ITíŒ€'
FROM auth.users
WHERE email IN ('admin@test.com', 'manager@test.com', 'user@test.com');
"

# 3. í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
echo "ğŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„± ì¤‘..."
ADMIN_ID=$(supabase db psql -t -c "SELECT id FROM user_profiles WHERE email = 'admin@test.com';")
USER_ID=$(supabase db psql -t -c "SELECT id FROM user_profiles WHERE email = 'user@test.com';")

supabase db psql -c "
INSERT INTO cost_records (
    registration_date, start_date, code, team, assignee_id, 
    cost_type, content, quantity, unit_price, amount, 
    status, created_by
) VALUES 
(
    CURRENT_DATE, CURRENT_DATE, 'TEST-001', 'ITíŒ€', '$USER_ID',
    'ì†”ë£¨ì…˜', 'RLS í…ŒìŠ¤íŠ¸ìš© ë°ì´í„°', 1, 100000, 100000,
    'ëŒ€ê¸°', '$USER_ID'
);
"

# 4. RLS ì •ì±… í…ŒìŠ¤íŠ¸ ì‹¤í–‰
echo "ğŸ” RLS ì •ì±… í…ŒìŠ¤íŠ¸ ì‹¤í–‰..."

# ì¼ë°˜ ì‚¬ìš©ìê°€ ë³¸ì¸ ë°ì´í„°ë§Œ ìˆ˜ì • ê°€ëŠ¥í•œì§€ í…ŒìŠ¤íŠ¸
echo "í…ŒìŠ¤íŠ¸ 1: ì‚¬ìš©ìê°€ ë³¸ì¸ ë°ì´í„°ë§Œ ìˆ˜ì • ê°€ëŠ¥í•œì§€ í™•ì¸"
RESULT=$(supabase db psql -t -c "
SET LOCAL \"request.jwt.claims\" TO '{\"sub\": \"$USER_ID\", \"role\": \"authenticated\"}';
UPDATE cost_records SET content = 'ìˆ˜ì •ëœ ë‚´ìš©' WHERE code = 'TEST-001';
SELECT ROW_COUNT();
" 2>/dev/null || echo "0")

if [ "$RESULT" = "1" ]; then
    echo "âœ… í…ŒìŠ¤íŠ¸ 1 í†µê³¼: ì‚¬ìš©ìê°€ ë³¸ì¸ ë°ì´í„° ìˆ˜ì • ê°€ëŠ¥"
else
    echo "âŒ í…ŒìŠ¤íŠ¸ 1 ì‹¤íŒ¨: ì‚¬ìš©ìê°€ ë³¸ì¸ ë°ì´í„° ìˆ˜ì • ë¶ˆê°€"
fi

# ê´€ë¦¬ìê°€ ëª¨ë“  ë°ì´í„° ì ‘ê·¼ ê°€ëŠ¥í•œì§€ í…ŒìŠ¤íŠ¸
echo "í…ŒìŠ¤íŠ¸ 2: ê´€ë¦¬ìê°€ ëª¨ë“  ë°ì´í„° ì ‘ê·¼ ê°€ëŠ¥í•œì§€ í™•ì¸"
ADMIN_ACCESS=$(supabase db psql -t -c "
SET LOCAL \"request.jwt.claims\" TO '{\"sub\": \"$ADMIN_ID\", \"role\": \"authenticated\"}';
SELECT COUNT(*) FROM cost_records;
" 2>/dev/null || echo "0")

if [ "$ADMIN_ACCESS" -gt "0" ]; then
    echo "âœ… í…ŒìŠ¤íŠ¸ 2 í†µê³¼: ê´€ë¦¬ìê°€ ëª¨ë“  ë°ì´í„° ì ‘ê·¼ ê°€ëŠ¥"
else
    echo "âŒ í…ŒìŠ¤íŠ¸ 2 ì‹¤íŒ¨: ê´€ë¦¬ìê°€ ë°ì´í„°ì— ì ‘ê·¼ ë¶ˆê°€"
fi

echo ""
echo "âœ… RLS ì •ì±… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!"
echo "ğŸ¯ ë‹¤ìŒ ë‹¨ê³„: Phase 5 - ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜"
EOF

chmod +x test-rls-policies.sh
```

---

## ğŸ“¦ Phase 5: ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ì „ ê°€ì´ë“œ (100% ë‹¬ì„±)

### âœ… 5.1 ì™„ì „ ìë™í™” ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸

#### ğŸ”„ ì „ì²´ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰
```bash
# migrate-all-data.sh ìƒì„±
cat > migrate-all-data.sh << 'EOF'
#!/bin/bash
set -e

echo "ğŸ“¦ ì „ì²´ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘..."

# 1. ë°±ì—… ìƒì„±
echo "ğŸ’¾ í˜„ì¬ ëª©ì—… ë°ì´í„° ë°±ì—… ìƒì„±..."
mkdir -p backups/$(date +%Y%m%d_%H%M%S)
BACKUP_DIR="backups/$(date +%Y%m%d_%H%M%S)"

# ëª©ì—… ë°ì´í„° ë°±ì—…
cp -r src/data/ $BACKUP_DIR/
echo "âœ… ë°±ì—… ì™„ë£Œ: $BACKUP_DIR"

# 2. ë§ˆì´ê·¸ë ˆì´ì…˜ ì§„í–‰ ìƒí™© ë¡œê¹…
exec > >(tee -a migration.log)
exec 2>&1

echo "ğŸ“‹ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘ ì‹œê°„: $(date)"

# 3. TypeScript ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ë° ì‹¤í–‰
cat > scripts/data-migration.ts << 'MIGRATION'
import { supabaseAdmin } from '@/lib/supabase'
import { costData } from '@/data/cost'
import { taskData } from '@/data/task'  
import { educationData } from '@/data/education'

interface MigrationStats {
  total: number
  success: number
  failed: number
  errors: string[]
}

class DataMigrator {
  private stats = {
    users: { total: 0, success: 0, failed: 0, errors: [] } as MigrationStats,
    costs: { total: 0, success: 0, failed: 0, errors: [] } as MigrationStats,
    tasks: { total: 0, success: 0, failed: 0, errors: [] } as MigrationStats,
    education: { total: 0, success: 0, failed: 0, errors: [] } as MigrationStats
  }

  async migrateAllData() {
    console.log('ğŸš€ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘...')
    
    try {
      await this.createDefaultUsers()
      await this.migrateCostData()
      await this.migrateTaskData()
      await this.migrateEducationData()
      
      this.printMigrationReport()
      console.log('âœ… ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ!')
    } catch (error) {
      console.error('âŒ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨:', error)
      throw error
    }
  }

  private async createDefaultUsers() {
    console.log('ğŸ‘¤ ê¸°ë³¸ ì‚¬ìš©ì ìƒì„± ì¤‘...')
    
    const defaultUsers = [
      { email: 'admin@nexwork.com', name: 'ì‹œìŠ¤í…œ ê´€ë¦¬ì', role: 'admin', department: 'ITíŒ€' },
      { email: 'kim@nexwork.com', name: 'ê¹€ì² ìˆ˜', role: 'user', department: 'ITíŒ€' },
      { email: 'park@nexwork.com', name: 'ë°•ì˜í¬', role: 'user', department: 'ë§ˆì¼€íŒ…íŒ€' },
      { email: 'lee@nexwork.com', name: 'ì´ë¯¼ìˆ˜', role: 'user', department: 'ITíŒ€' },
      { email: 'choi@nexwork.com', name: 'ìµœìœ¤ì •', role: 'user', department: 'ì˜ì—…íŒ€' },
      { email: 'jung@nexwork.com', name: 'ì •ìƒí˜„', role: 'manager', department: 'ê¸°íšíŒ€' }
    ]

    this.stats.users.total = defaultUsers.length

    for (const userData of defaultUsers) {
      try {
        // 1. Auth ì‚¬ìš©ì ìƒì„±
        const { data: authUser, error: authError } = await supabaseAdmin.auth.admin.createUser({
          email: userData.email,
          password: 'temp123456!',
          email_confirm: true,
          user_metadata: {
            name: userData.name
          }
        })

        if (authError) throw authError

        // 2. í”„ë¡œí•„ ìƒì„±
        const { error: profileError } = await supabaseAdmin
          .from('user_profiles')
          .insert({
            id: authUser.user.id,
            email: userData.email,
            name: userData.name,
            role: userData.role,
            department: userData.department
          })

        if (profileError) throw profileError

        this.stats.users.success++
        console.log(`âœ… ì‚¬ìš©ì ìƒì„± ì™„ë£Œ: ${userData.name}`)
      } catch (error) {
        this.stats.users.failed++
        this.stats.users.errors.push(`${userData.name}: ${error.message}`)
        console.error(`âŒ ì‚¬ìš©ì ìƒì„± ì‹¤íŒ¨: ${userData.name}`, error)
      }
    }
  }

  private async migrateCostData() {
    console.log('ğŸ’° ë¹„ìš© ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì¤‘...')
    
    this.stats.costs.total = costData.length

    for (const record of costData) {
      try {
        // ë‹´ë‹¹ì ID ì°¾ê¸°
        const assigneeId = await this.getUserIdByName(record.assignee)
        
        // ë¹„ìš© ê¸°ë¡ ìƒì„±
        const { data: newRecord, error: recordError } = await supabaseAdmin
          .from('cost_records')
          .insert({
            registration_date: record.registrationDate,
            start_date: record.startDate,
            code: record.code,
            team: record.team,
            assignee_id: assigneeId,
            cost_type: record.costType,
            content: record.content,
            quantity: record.quantity,
            unit_price: record.unitPrice,
            amount: record.amount,
            status: record.status,
            completion_date: record.completionDate || null,
            created_by: assigneeId
          })
          .select()
          .single()

        if (recordError) throw recordError

        // ëŒ“ê¸€ ë§ˆì´ê·¸ë ˆì´ì…˜
        if (record.comments?.length > 0) {
          for (const comment of record.comments) {
            const commentAuthorId = await this.getUserIdByName(comment.author)
            await supabaseAdmin
              .from('cost_comments')
              .insert({
                cost_record_id: newRecord.id,
                author_id: commentAuthorId,
                content: comment.content,
                timestamp: comment.timestamp
              })
          }
        }

        // ì²¨ë¶€íŒŒì¼ ì •ë³´ ë§ˆì´ê·¸ë ˆì´ì…˜
        if (record.attachments?.length > 0) {
          for (const attachment of record.attachments) {
            await supabaseAdmin
              .from('cost_attachments')
              .insert({
                cost_record_id: newRecord.id,
                name: attachment.name,
                file_type: attachment.type,
                file_size: this.parseFileSize(attachment.size),
                storage_path: `migrated/${attachment.name}`,
                upload_date: attachment.uploadDate,
                uploaded_by: assigneeId
              })
          }
        }

        this.stats.costs.success++
        console.log(`âœ… ë¹„ìš© ê¸°ë¡ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ: ${record.code}`)
      } catch (error) {
        this.stats.costs.failed++
        this.stats.costs.errors.push(`${record.code}: ${error.message}`)
        console.error(`âŒ ë¹„ìš© ê¸°ë¡ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: ${record.code}`, error)
      }
    }
  }

  private async migrateTaskData() {
    console.log('ğŸ“‹ ì—…ë¬´ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì¤‘...')
    
    this.stats.tasks.total = taskData.length

    for (const record of taskData) {
      try {
        const assigneeId = await this.getUserIdByName(record.assignee)
        
        const { error } = await supabaseAdmin
          .from('task_records')
          .insert({
            registration_date: record.registrationDate,
            code: record.code,
            team: record.team,
            department: record.department,
            work_content: record.workContent,
            status: record.status,
            assignee_id: assigneeId,
            start_date: record.startDate || null,
            completed_date: record.completedDate || null,
            created_by: assigneeId
          })

        if (error) throw error

        this.stats.tasks.success++
        console.log(`âœ… ì—…ë¬´ ê¸°ë¡ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ: ${record.code}`)
      } catch (error) {
        this.stats.tasks.failed++
        this.stats.tasks.errors.push(`${record.code}: ${error.message}`)
        console.error(`âŒ ì—…ë¬´ ê¸°ë¡ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: ${record.code}`, error)
      }
    }
  }

  private async migrateEducationData() {
    console.log('ğŸ“š êµìœ¡ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì¤‘...')
    
    this.stats.education.total = educationData.length

    for (const record of educationData) {
      try {
        const assigneeId = await this.getUserIdByName(record.assignee)
        
        // êµìœ¡ ê¸°ë¡ ìƒì„±
        const { data: newRecord, error: recordError } = await supabaseAdmin
          .from('education_records')
          .insert({
            registration_date: record.registrationDate,
            start_date: record.startDate,
            code: record.code,
            education_type: record.educationType,
            content: record.content,
            participants: record.participants,
            location: record.location,
            status: record.status,
            completion_date: record.completionDate || null,
            assignee_id: assigneeId,
            created_by: assigneeId
          })
          .select()
          .single()

        if (recordError) throw recordError

        // ì»¤ë¦¬í˜ëŸ¼ ë§ˆì´ê·¸ë ˆì´ì…˜
        if (record.curriculum?.length > 0) {
          await supabaseAdmin
            .from('education_curriculum')
            .insert(
              record.curriculum.map((item, index) => ({
                education_record_id: newRecord.id,
                time_slot: item.time,
                subject: item.subject,
                instructor: item.instructor,
                content: item.content,
                attachment_path: item.attachment,
                sort_order: index
              }))
            )
        }

        // ì°¸ì„ì ë§ˆì´ê·¸ë ˆì´ì…˜
        if (record.participantList?.length > 0) {
          await supabaseAdmin
            .from('education_participants')
            .insert(
              record.participantList.map(item => ({
                education_record_id: newRecord.id,
                participant_name: item.name,
                department: item.department,
                position: item.position,
                attendance: item.attendance,
                report_path: item.report,
                note: item.note
              }))
            )
        }

        // êµìœ¡ ì‹¤ì  ë§ˆì´ê·¸ë ˆì´ì…˜
        if (record.result) {
          await supabaseAdmin
            .from('education_results')
            .insert({
              education_record_id: newRecord.id,
              performance: record.result.performance,
              improvement: record.result.improvement,
              feedback: record.result.feedback
            })
        }

        this.stats.education.success++
        console.log(`âœ… êµìœ¡ ê¸°ë¡ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ: ${record.code}`)
      } catch (error) {
        this.stats.education.failed++
        this.stats.education.errors.push(`${record.code}: ${error.message}`)
        console.error(`âŒ êµìœ¡ ê¸°ë¡ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: ${record.code}`, error)
      }
    }
  }

  private async getUserIdByName(name: string): Promise<string | null> {
    const { data } = await supabaseAdmin
      .from('user_profiles')
      .select('id')
      .eq('name', name)
      .single()
    
    return data?.id || null
  }

  private parseFileSize(sizeStr: string): number {
    const match = sizeStr.match(/([\d.]+)\s*(MB|KB|GB)/i)
    if (!match) return 0
    
    const value = parseFloat(match[1])
    const unit = match[2].toUpperCase()
    
    switch (unit) {
      case 'KB': return value * 1024
      case 'MB': return value * 1024 * 1024
      case 'GB': return value * 1024 * 1024 * 1024
      default: return value
    }
  }

  private printMigrationReport() {
    console.log('\nğŸ“Š ë§ˆì´ê·¸ë ˆì´ì…˜ ê²°ê³¼ ë¦¬í¬íŠ¸')
    console.log('================================')
    
    const categories = ['users', 'costs', 'tasks', 'education']
    const categoryNames = ['ì‚¬ìš©ì', 'ë¹„ìš©', 'ì—…ë¬´', 'êµìœ¡']
    
    categories.forEach((category, index) => {
      const stats = this.stats[category]
      console.log(`\n${categoryNames[index]}:`)
      console.log(`  ì „ì²´: ${stats.total}`)
      console.log(`  ì„±ê³µ: ${stats.success}`)
      console.log(`  ì‹¤íŒ¨: ${stats.failed}`)
      console.log(`  ì„±ê³µë¥ : ${((stats.success / stats.total) * 100).toFixed(1)}%`)
      
      if (stats.errors.length > 0) {
        console.log('  ì˜¤ë¥˜:')
        stats.errors.forEach(error => console.log(`    - ${error}`))
      }
    })

    const totalRecords = Object.values(this.stats).reduce((sum, stat) => sum + stat.total, 0)
    const totalSuccess = Object.values(this.stats).reduce((sum, stat) => sum + stat.success, 0)
    const totalFailed = Object.values(this.stats).reduce((sum, stat) => sum + stat.failed, 0)

    console.log('\nğŸ“ˆ ì „ì²´ ìš”ì•½:')
    console.log(`  ì „ì²´ ë ˆì½”ë“œ: ${totalRecords}`)
    console.log(`  ì„±ê³µ: ${totalSuccess}`)
    console.log(`  ì‹¤íŒ¨: ${totalFailed}`)
    console.log(`  ì „ì²´ ì„±ê³µë¥ : ${((totalSuccess / totalRecords) * 100).toFixed(1)}%`)
  }
}

// ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰
const migrator = new DataMigrator()
migrator.migrateAllData().catch(console.error)
MIGRATION

# 4. TypeScript ì»´íŒŒì¼ ë° ì‹¤í–‰
echo "ğŸ”„ ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì¤‘..."
npx tsx scripts/data-migration.ts

# 5. ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦
echo "ğŸ” ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦ ì¤‘..."
./verify-migration.sh

echo "ğŸ“‹ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ ì‹œê°„: $(date)"
EOF

chmod +x migrate-all-data.sh
```

#### ğŸ” ë§ˆì´ê·¸ë ˆì´ì…˜ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸
```bash
# verify-migration.sh ìƒì„±
cat > verify-migration.sh << 'EOF'
#!/bin/bash
set -e

echo "ğŸ” ë§ˆì´ê·¸ë ˆì´ì…˜ ê²°ê³¼ ê²€ì¦ ì¤‘..."

# 1. ë ˆì½”ë“œ ìˆ˜ í™•ì¸
echo "ğŸ“Š ë ˆì½”ë“œ ìˆ˜ ê²€ì¦..."
USER_COUNT=$(supabase db psql -t -c "SELECT COUNT(*) FROM user_profiles;")
COST_COUNT=$(supabase db psql -t -c "SELECT COUNT(*) FROM cost_records;")
TASK_COUNT=$(supabase db psql -t -c "SELECT COUNT(*) FROM task_records;")
EDU_COUNT=$(supabase db psql -t -c "SELECT COUNT(*) FROM education_records;")

echo "ì‚¬ìš©ì: $USER_COUNT"
echo "ë¹„ìš© ê¸°ë¡: $COST_COUNT"
echo "ì—…ë¬´ ê¸°ë¡: $TASK_COUNT"
echo "êµìœ¡ ê¸°ë¡: $EDU_COUNT"

# 2. ì™¸ë˜í‚¤ ì°¸ì¡° ë¬´ê²°ì„± í™•ì¸
echo "ğŸ”— ì°¸ì¡° ë¬´ê²°ì„± í™•ì¸..."
ORPHAN_COSTS=$(supabase db psql -t -c "SELECT COUNT(*) FROM cost_records WHERE assignee_id NOT IN (SELECT id FROM user_profiles);")
ORPHAN_TASKS=$(supabase db psql -t -c "SELECT COUNT(*) FROM task_records WHERE assignee_id NOT IN (SELECT id FROM user_profiles);")

if [ "$ORPHAN_COSTS" -eq "0" ] && [ "$ORPHAN_TASKS" -eq "0" ]; then
    echo "âœ… ì™¸ë˜í‚¤ ì°¸ì¡° ë¬´ê²°ì„± ì •ìƒ"
else
    echo "âŒ ì°¸ì¡° ë¬´ê²°ì„± ë¬¸ì œ ë°œê²¬ - ê³ ì•„ ë ˆì½”ë“œ: ë¹„ìš©($ORPHAN_COSTS), ì—…ë¬´($ORPHAN_TASKS)"
fi

# 3. ê¸ˆì•¡ ê³„ì‚° ì •í™•ì„± ê²€ì¦
echo "ğŸ’° ê¸ˆì•¡ ê³„ì‚° ê²€ì¦..."
AMOUNT_ERRORS=$(supabase db psql -t -c "SELECT COUNT(*) FROM cost_records WHERE amount != quantity * unit_price;")

if [ "$AMOUNT_ERRORS" -eq "0" ]; then
    echo "âœ… ê¸ˆì•¡ ê³„ì‚° ì •í™•ì„± ì •ìƒ"
else
    echo "âŒ ê¸ˆì•¡ ê³„ì‚° ì˜¤ë¥˜ $AMOUNT_ERRORSê±´ ë°œê²¬"
fi

# 4. ìƒ˜í”Œ ë°ì´í„° ìˆ˜ë™ ê²€ì¦
echo "ğŸ” ìƒ˜í”Œ ë°ì´í„° ê²€ì¦..."
supabase db psql -c "
SELECT 
    cr.code,
    cr.content,
    cr.amount,
    up.name as assignee_name
FROM cost_records cr
LEFT JOIN user_profiles up ON cr.assignee_id = up.id
LIMIT 5;
"

echo ""
echo "âœ… ë§ˆì´ê·¸ë ˆì´ì…˜ ê²€ì¦ ì™„ë£Œ!"
echo "ğŸ¯ ë‹¤ìŒ ë‹¨ê³„: Phase 6 - API ë° í”„ë¡ íŠ¸ì—”ë“œ í†µí•©"
EOF

chmod +x verify-migration.sh
```

---

## ğŸ”Œ Phase 6: API ë° í”„ë¡ íŠ¸ì—”ë“œ í†µí•© ì™„ì „ ê°€ì´ë“œ (100% ë‹¬ì„±)

### âœ… 6.1 Supabase í´ë¼ì´ì–¸íŠ¸ ì™„ì „ í†µí•©

#### ğŸš€ íƒ€ì… ì•ˆì „í•œ API í´ë˜ìŠ¤ ìƒì„±
```bash
# generate-api-classes.sh ìƒì„±
cat > generate-api-classes.sh << 'EOF'
#!/bin/bash
set -e

echo "ğŸ”§ API í´ë˜ìŠ¤ ìƒì„± ì¤‘..."

# 1. ë°ì´í„°ë² ì´ìŠ¤ íƒ€ì… ìƒì„±
echo "ğŸ“ TypeScript íƒ€ì… ìƒì„± ì¤‘..."
npx supabase gen types typescript --project-id $(grep NEXT_PUBLIC_SUPABASE_URL .env.local | cut -d'=' -f2 | cut -d'/' -f3 | cut -d'.' -f1) > types/database.types.ts

# 2. ë¹„ìš©ê´€ë¦¬ API í´ë˜ìŠ¤
mkdir -p lib/api
cat > lib/api/cost.ts << 'COST_API'
import { supabase } from '@/lib/supabase'
import { Database } from '@/types/database.types'

type CostRecord = Database['public']['Tables']['cost_records']['Row']
type CostRecordInsert = Database['public']['Tables']['cost_records']['Insert']
type CostRecordUpdate = Database['public']['Tables']['cost_records']['Update']

export class CostAPI {
  // ë¹„ìš© ëª©ë¡ ì¡°íšŒ (í•„í„°ë§ í¬í•¨)
  static async getCostRecords(filters?: {
    team?: string
    status?: string
    assignee?: string
    dateRange?: { start: string; end: string }
  }) {
    let query = supabase
      .from('cost_records')
      .select(`
        *,
        assignee:user_profiles(name, email, avatar_url),
        comments:cost_comments(
          id, content, timestamp,
          author:user_profiles(name, avatar_url)
        ),
        attachments:cost_attachments(*),
        amount_details:cost_amount_details(*)
      `)

    // í•„í„° ì ìš©
    if (filters?.team) {
      query = query.eq('team', filters.team)
    }
    if (filters?.status) {
      query = query.eq('status', filters.status)
    }
    if (filters?.assignee) {
      query = query.eq('assignee_id', filters.assignee)
    }
    if (filters?.dateRange) {
      query = query
        .gte('registration_date', filters.dateRange.start)
        .lte('registration_date', filters.dateRange.end)
    }

    return query.order('registration_date', { ascending: false })
  }

  // ë¹„ìš© ê¸°ë¡ ìƒì„±
  static async createCostRecord(data: Omit<CostRecordInsert, 'id' | 'created_at' | 'updated_at'>) {
    const { data: { user } } = await supabase.auth.getUser()
    if (!user) throw new Error('ì¸ì¦ë˜ì§€ ì•Šì€ ì‚¬ìš©ì')

    // ì½”ë“œ ìë™ ìƒì„±
    const year = new Date().getFullYear()
    const { data: sequence } = await supabase.rpc('get_next_sequence', {
      p_module_type: 'COST',
      p_year: year
    })

    const code = `COST-${year.toString().slice(-2)}-${String(sequence).padStart(3, '0')}`

    const { data: newRecord, error } = await supabase
      .from('cost_records')
      .insert({
        ...data,
        code,
        created_by: user.id
      })
      .select(`
        *,
        assignee:user_profiles(name, email)
      `)
      .single()

    if (error) throw error
    return newRecord
  }

  // ë¹„ìš© ê¸°ë¡ ìˆ˜ì •
  static async updateCostRecord(id: string, data: CostRecordUpdate) {
    const { data: updatedRecord, error } = await supabase
      .from('cost_records')
      .update(data)
      .eq('id', id)
      .select(`
        *,
        assignee:user_profiles(name, email)
      `)
      .single()

    if (error) throw error
    return updatedRecord
  }

  // ë¹„ìš© ê¸°ë¡ ì‚­ì œ
  static async deleteCostRecord(id: string) {
    const { error } = await supabase
      .from('cost_records')
      .delete()
      .eq('id', id)

    if (error) throw error
  }

  // ëŒ“ê¸€ ì¶”ê°€
  static async addComment(costRecordId: string, content: string) {
    const { data: { user } } = await supabase.auth.getUser()
    if (!user) throw new Error('ì¸ì¦ë˜ì§€ ì•Šì€ ì‚¬ìš©ì')

    const { data: comment, error } = await supabase
      .from('cost_comments')
      .insert({
        cost_record_id: costRecordId,
        author_id: user.id,
        content
      })
      .select(`
        *,
        author:user_profiles(name, avatar_url)
      `)
      .single()

    if (error) throw error
    return comment
  }

  // íŒŒì¼ ì—…ë¡œë“œ
  static async uploadFile(costRecordId: string, file: File) {
    const { data: { user } } = await supabase.auth.getUser()
    if (!user) throw new Error('ì¸ì¦ë˜ì§€ ì•Šì€ ì‚¬ìš©ì')

    const fileExt = file.name.split('.').pop()
    const fileName = `${costRecordId}/${Date.now()}.${fileExt}`

    // íŒŒì¼ ì—…ë¡œë“œ
    const { data: uploadData, error: uploadError } = await supabase.storage
      .from('cost-attachments')
      .upload(fileName, file, {
        cacheControl: '3600',
        upsert: false
      })

    if (uploadError) throw uploadError

    // ë©”íƒ€ë°ì´í„° ì €ì¥
    const { data: attachment, error: dbError } = await supabase
      .from('cost_attachments')
      .insert({
        cost_record_id: costRecordId,
        name: file.name,
        file_type: file.type,
        file_size: file.size,
        storage_path: fileName,
        uploaded_by: user.id
      })
      .select()
      .single()

    if (dbError) throw dbError
    return attachment
  }

  // íŒŒì¼ ë‹¤ìš´ë¡œë“œ URL ìƒì„±
  static async getFileDownloadUrl(storagePath: string) {
    const { data } = await supabase.storage
      .from('cost-attachments')
      .createSignedUrl(storagePath, 3600) // 1ì‹œê°„ ìœ íš¨

    return data?.signedUrl
  }

  // í†µê³„ ë°ì´í„° ì¡°íšŒ
  static async getCostStatistics() {
    const { data: records } = await this.getCostRecords()
    
    if (!records) return null

    const totalAmount = records.reduce((sum, record) => sum + record.amount, 0)
    const statusStats = records.reduce((acc, record) => {
      acc[record.status] = (acc[record.status] || 0) + 1
      return acc
    }, {} as Record<string, number>)

    const typeStats = records.reduce((acc, record) => {
      acc[record.cost_type] = (acc[record.cost_type] || 0) + record.amount
      return acc
    }, {} as Record<string, number>)

    return {
      totalAmount,
      totalCount: records.length,
      statusStats,
      typeStats
    }
  }
}
COST_API

# 3. ì—…ë¬´ê´€ë¦¬ API í´ë˜ìŠ¤  
cat > lib/api/task.ts << 'TASK_API'
import { supabase } from '@/lib/supabase'
import { Database } from '@/types/database.types'

type TaskRecord = Database['public']['Tables']['task_records']['Row']
type TaskRecordInsert = Database['public']['Tables']['task_records']['Insert']
type TaskRecordUpdate = Database['public']['Tables']['task_records']['Update']

export class TaskAPI {
  static async getTaskRecords(filters?: {
    department?: string
    status?: string
    assignee?: string
    team?: string
  }) {
    let query = supabase
      .from('task_records')
      .select(`
        *,
        assignee:user_profiles(name, email, avatar_url),
        attachments:task_attachments(*)
      `)

    if (filters?.department) {
      query = query.eq('department', filters.department)
    }
    if (filters?.status) {
      query = query.eq('status', filters.status)
    }
    if (filters?.assignee) {
      query = query.eq('assignee_id', filters.assignee)
    }
    if (filters?.team) {
      query = query.eq('team', filters.team)
    }

    return query.order('created_at', { ascending: false })
  }

  static async createTaskRecord(data: Omit<TaskRecordInsert, 'id' | 'code' | 'created_at' | 'updated_at'>) {
    const { data: { user } } = await supabase.auth.getUser()
    if (!user) throw new Error('ì¸ì¦ë˜ì§€ ì•Šì€ ì‚¬ìš©ì')

    // ìë™ ì½”ë“œ ìƒì„±
    const year = new Date().getFullYear()
    const { data: sequence } = await supabase.rpc('get_next_sequence', {
      p_module_type: 'TASK',
      p_year: year
    })

    const code = `TASK-${year.toString().slice(-2)}-${String(sequence).padStart(3, '0')}`

    const { data: newRecord, error } = await supabase
      .from('task_records')
      .insert({
        ...data,
        code,
        created_by: user.id
      })
      .select(`
        *,
        assignee:user_profiles(name, email)
      `)
      .single()

    if (error) throw error
    return newRecord
  }

  static async updateTaskRecord(id: string, data: TaskRecordUpdate) {
    const { data: updatedRecord, error } = await supabase
      .from('task_records')
      .update(data)
      .eq('id', id)
      .select(`
        *,
        assignee:user_profiles(name, email)
      `)
      .single()

    if (error) throw error
    return updatedRecord
  }

  static async deleteTaskRecord(id: string) {
    const { error } = await supabase
      .from('task_records')
      .delete()
      .eq('id', id)

    if (error) throw error
  }
}
TASK_API

# 4. êµìœ¡ê´€ë¦¬ API í´ë˜ìŠ¤
cat > lib/api/education.ts << 'EDU_API'
import { supabase } from '@/lib/supabase'
import { Database } from '@/types/database.types'

type EducationRecord = Database['public']['Tables']['education_records']['Row']
type EducationRecordInsert = Database['public']['Tables']['education_records']['Insert']

export class EducationAPI {
  static async getEducationRecords() {
    return supabase
      .from('education_records')
      .select(`
        *,
        assignee:user_profiles(name, email),
        curriculum:education_curriculum(*),
        participants:education_participants(*),
        result:education_results(*)
      `)
      .order('start_date', { ascending: false })
  }

  static async createEducationRecord(data: {
    main: Omit<EducationRecordInsert, 'id' | 'code' | 'created_at' | 'updated_at'>
    curriculum: Array<{
      time_slot: string
      subject: string
      instructor: string
      content: string
      attachment_path?: string
    }>
    participants: Array<{
      participant_name: string
      department: string
      position: string
      attendance?: string
    }>
  }) {
    const { data: { user } } = await supabase.auth.getUser()
    if (!user) throw new Error('ì¸ì¦ë˜ì§€ ì•Šì€ ì‚¬ìš©ì')

    // íŠ¸ëœì­ì…˜ ì²˜ë¦¬ë¥¼ ìœ„í•œ RPC í•¨ìˆ˜ í˜¸ì¶œ
    const year = new Date().getFullYear()
    const { data: sequence } = await supabase.rpc('get_next_sequence', {
      p_module_type: 'EDU',
      p_year: year
    })

    const typeCode = {
      'ì‹ ì…êµìœ¡': 'I',
      'ë‹´ë‹¹ìêµìœ¡': 'S',
      'ê´€ë¦¬ìêµìœ¡': 'M',  
      'ìˆ˜ì‹œêµìœ¡': 'A'
    }[data.main.education_type]

    const code = `EDU-${typeCode}-${year.toString().slice(-2)}-${String(sequence).padStart(3, '0')}`

    // ë©”ì¸ ë ˆì½”ë“œ ìƒì„±
    const { data: newRecord, error: recordError } = await supabase
      .from('education_records')
      .insert({
        ...data.main,
        code,
        created_by: user.id
      })
      .select()
      .single()

    if (recordError) throw recordError

    // ì»¤ë¦¬í˜ëŸ¼ ì¶”ê°€
    if (data.curriculum.length > 0) {
      const { error: curriculumError } = await supabase
        .from('education_curriculum')
        .insert(
          data.curriculum.map((item, index) => ({
            ...item,
            education_record_id: newRecord.id,
            sort_order: index
          }))
        )

      if (curriculumError) throw curriculumError
    }

    // ì°¸ì„ì ì¶”ê°€
    if (data.participants.length > 0) {
      const { error: participantsError } = await supabase
        .from('education_participants')
        .insert(
          data.participants.map(item => ({
            ...item,
            education_record_id: newRecord.id
          }))
        )

      if (participantsError) throw participantsError
    }

    return newRecord
  }
}
EDU_API

echo "âœ… API í´ë˜ìŠ¤ ìƒì„± ì™„ë£Œ!"
echo "ğŸ¯ ë‹¤ìŒ ë‹¨ê³„: React Hook ìƒì„±"
EOF

chmod +x generate-api-classes.sh
./generate-api-classes.sh
```

#### Phase 3: í•µì‹¬ ëª¨ë“ˆ ë§ˆì´ê·¸ë ˆì´ì…˜ (2-3ì£¼)

**Week 1: ë¹„ìš©ê´€ë¦¬ ëª¨ë“ˆ**
```typescript
// ê¸°ì¡´ ëª©ì—… ë°ì´í„°ë¥¼ Supabaseë¡œ ì´ì „
async function migrateCostData() {
  const existingData = await import('@/data/cost')
  
  for (const record of existingData.costData) {
    await supabase
      .from('cost_records')
      .insert({
        ...record,
        assignee_id: await getUserIdByName(record.assignee),
        created_by: 'system-migration'
      })
  }
}
```

**Week 2: ì—…ë¬´ê´€ë¦¬ ëª¨ë“ˆ**
- Task ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜
- ì¹¸ë°˜ ë³´ë“œ ì‹¤ì‹œê°„ ë™ê¸°í™” êµ¬í˜„

**Week 3: êµìœ¡ê´€ë¦¬ ëª¨ë“ˆ**
- Education ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜
- ë³µì¡í•œ ê´€ê³„í˜• ë°ì´í„° ì²˜ë¦¬

#### Phase 4: ê³ ê¸‰ ê¸°ëŠ¥ êµ¬í˜„ (1-2ì£¼)
1. **ì‹¤ì‹œê°„ ê¸°ëŠ¥ êµ¬í˜„**
2. **íŒŒì¼ ì—…ë¡œë“œ/ë‹¤ìš´ë¡œë“œ ì‹œìŠ¤í…œ**
3. **ê²€ìƒ‰ ë° í•„í„°ë§ ìµœì í™”**
4. **ë¦¬í¬íŠ¸ ìƒì„± ì‹œìŠ¤í…œ**

#### Phase 5: ì„±ëŠ¥ ìµœì í™” ë° í…ŒìŠ¤íŒ… (1ì£¼)
1. **ì¿¼ë¦¬ ìµœì í™”**
2. **ì¸ë±ìŠ¤ íŠœë‹**
3. **ë¡œë“œ í…ŒìŠ¤íŒ…**
4. **ë³´ì•ˆ ê°ì‚¬**

### 7.2 ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸

```typescript
// scripts/migrate-data.ts
import { supabase } from '@/lib/supabase'
import { costData } from '@/data/cost'
import { taskData } from '@/data/task'
import { educationData } from '@/data/education'

class DataMigrator {
  async migrateAllData() {
    console.log('ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘...')
    
    try {
      await this.createDefaultUsers()
      await this.migrateCostData()
      await this.migrateTaskData()
      await this.migrateEducationData()
      
      console.log('ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ!')
    } catch (error) {
      console.error('ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨:', error)
    }
  }

  private async createDefaultUsers() {
    const defaultUsers = [
      { email: 'admin@nexwork.com', name: 'ê´€ë¦¬ì', role: 'admin' },
      { email: 'kim@nexwork.com', name: 'ê¹€ì² ìˆ˜', role: 'user' },
      // ... ë” ë§ì€ ì‚¬ìš©ì
    ]

    for (const user of defaultUsers) {
      const { data: authUser, error: authError } = await supabase.auth.admin.createUser({
        email: user.email,
        password: 'temp123456',
        email_confirm: true
      })

      if (!authError && authUser.user) {
        await supabase
          .from('user_profiles')
          .insert({
            id: authUser.user.id,
            email: user.email,
            name: user.name,
            role: user.role
          })
      }
    }
  }

  private async migrateCostData() {
    console.log('ë¹„ìš© ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì¤‘...')
    
    for (const record of costData) {
      const assigneeId = await this.getUserIdByName(record.assignee)
      
      const { data: newRecord, error } = await supabase
        .from('cost_records')
        .insert({
          registration_date: record.registrationDate,
          start_date: record.startDate,
          code: record.code,
          team: record.team,
          assignee_id: assigneeId,
          cost_type: record.costType,
          content: record.content,
          quantity: record.quantity,
          unit_price: record.unitPrice,
          amount: record.amount,
          status: record.status,
          completion_date: record.completionDate || null
        })
        .select()
        .single()

      if (error) {
        console.error(`ë¹„ìš© ê¸°ë¡ ${record.code} ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨:`, error)
        continue
      }

      // ì²¨ë¶€íŒŒì¼ ì •ë³´ ë§ˆì´ê·¸ë ˆì´ì…˜
      if (record.attachments?.length > 0) {
        for (const attachment of record.attachments) {
          await supabase
            .from('cost_attachments')
            .insert({
              cost_record_id: newRecord.id,
              name: attachment.name,
              file_type: attachment.type,
              file_size: this.parseFileSize(attachment.size),
              storage_path: `migrated/${attachment.name}`,
              upload_date: attachment.uploadDate
            })
        }
      }
    }
  }

  private async getUserIdByName(name: string): Promise<string | null> {
    const { data } = await supabase
      .from('user_profiles')
      .select('id')
      .eq('name', name)
      .single()
    
    return data?.id || null
  }

  private parseFileSize(sizeStr: string): number {
    const match = sizeStr.match(/([\d.]+)\s*(MB|KB|GB)/i)
    if (!match) return 0
    
    const value = parseFloat(match[1])
    const unit = match[2].toUpperCase()
    
    switch (unit) {
      case 'KB': return value * 1024
      case 'MB': return value * 1024 * 1024
      case 'GB': return value * 1024 * 1024 * 1024
      default: return value
    }
  }
}

// ì‹¤í–‰
const migrator = new DataMigrator()
migrator.migrateAllData()
```

## ğŸ”§ 8. ë°°í¬ ë° ìš´ì˜ ê³„íš

### 8.1 í™˜ê²½ë³„ ì„¤ì •

#### ê°œë°œ í™˜ê²½
```yaml
# .env.development
NEXT_PUBLIC_SUPABASE_URL=http://localhost:54321
NEXT_PUBLIC_SUPABASE_ANON_KEY=local_anon_key
SUPABASE_SERVICE_ROLE_KEY=local_service_role_key
```

#### ìŠ¤í…Œì´ì§• í™˜ê²½
```yaml
# .env.staging
NEXT_PUBLIC_SUPABASE_URL=https://staging-project.supabase.co
NEXT_PUBLIC_SUPABASE_ANON_KEY=staging_anon_key
SUPABASE_SERVICE_ROLE_KEY=staging_service_role_key
```

#### í”„ë¡œë•ì…˜ í™˜ê²½
```yaml
# .env.production
NEXT_PUBLIC_SUPABASE_URL=https://prod-project.supabase.co
NEXT_PUBLIC_SUPABASE_ANON_KEY=prod_anon_key
SUPABASE_SERVICE_ROLE_KEY=prod_service_role_key
```

### 8.2 CI/CD íŒŒì´í”„ë¼ì¸

```yaml
# .github/workflows/deploy.yml
name: Deploy to Supabase

on:
  push:
    branches: [main, staging]

jobs:
  deploy:
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'
          
      - name: Install dependencies
        run: npm ci
        
      - name: Run tests
        run: npm test
        
      - name: Build application
        run: npm run build
        
      - name: Setup Supabase CLI
        uses: supabase/setup-cli@v1
        
      - name: Deploy to Supabase
        run: |
          supabase link --project-ref ${{ secrets.SUPABASE_PROJECT_REF }}
          supabase db push
        env:
          SUPABASE_ACCESS_TOKEN: ${{ secrets.SUPABASE_ACCESS_TOKEN }}
          
      - name: Deploy to Vercel
        uses: vercel/action@v1
        with:
          vercel-token: ${{ secrets.VERCEL_TOKEN }}
          vercel-project-id: ${{ secrets.VERCEL_PROJECT_ID }}
```

### 8.3 ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹…

```typescript
// lib/monitoring.ts
import { supabase } from '@/lib/supabase'

export class MonitoringService {
  static async logActivity(
    action: string,
    tableName: string,
    recordId?: string,
    oldValues?: any,
    newValues?: any
  ) {
    const { data: { user } } = await supabase.auth.getUser()
    
    await supabase
      .from('activity_logs')
      .insert({
        user_id: user?.id,
        action,
        table_name: tableName,
        record_id: recordId,
        old_values: oldValues,
        new_values: newValues,
        ip_address: await this.getClientIP()
      })
  }

  static async getClientIP(): Promise<string> {
    try {
      const response = await fetch('https://api.ipify.org?format=json')
      const data = await response.json()
      return data.ip
    } catch {
      return 'unknown'
    }
  }

  // ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
  static async trackQueryPerformance(
    queryName: string,
    startTime: number
  ) {
    const duration = Date.now() - startTime
    
    if (duration > 1000) { // 1ì´ˆ ì´ìƒ ê±¸ë¦° ì¿¼ë¦¬ ë¡œê¹…
      console.warn(`Slow query detected: ${queryName} took ${duration}ms`)
      
      await supabase
        .from('performance_logs')
        .insert({
          query_name: queryName,
          duration_ms: duration,
          timestamp: new Date()
        })
    }
  }
}
```

### 8.4 ë°±ì—… ë° ë³µêµ¬ ê³„íš

```bash
# ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—… ìŠ¤í¬ë¦½íŠ¸
#!/bin/bash
# backup.sh

TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
BACKUP_DIR="/backups/supabase"

# PostgreSQL ë¤í”„ ìƒì„±
pg_dump $DATABASE_URL > "$BACKUP_DIR/backup_$TIMESTAMP.sql"

# Supabase Storage ë°±ì—…
supabase storage download --project-ref $PROJECT_REF

# ë°±ì—… íŒŒì¼ ì••ì¶•
gzip "$BACKUP_DIR/backup_$TIMESTAMP.sql"

# 30ì¼ ì´ìƒ ëœ ë°±ì—… íŒŒì¼ ì‚­ì œ
find $BACKUP_DIR -name "backup_*.sql.gz" -mtime +30 -delete

echo "ë°±ì—… ì™„ë£Œ: backup_$TIMESTAMP.sql.gz"
```

## ğŸ“Š 9. ì„±ëŠ¥ ìµœì í™” ë°©ì•ˆ

### 9.1 ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™”

```sql
-- ì¸ë±ìŠ¤ ìµœì í™”
CREATE INDEX CONCURRENTLY idx_cost_records_compound 
ON cost_records (status, team, registration_date DESC);

CREATE INDEX CONCURRENTLY idx_task_records_assignee_status 
ON task_records (assignee_id, status) WHERE status != 'ì™„ë£Œ';

-- íŒŒí‹°ì…”ë‹ (ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ìš©)
CREATE TABLE cost_records_2024 PARTITION OF cost_records
FOR VALUES FROM ('2024-01-01') TO ('2025-01-01');

CREATE TABLE cost_records_2025 PARTITION OF cost_records  
FOR VALUES FROM ('2025-01-01') TO ('2026-01-01');

-- í†µê³„ ì •ë³´ ì—…ë°ì´íŠ¸ ìë™í™”
CREATE EXTENSION IF NOT EXISTS pg_cron;

SELECT cron.schedule(
  'update-table-stats',
  '0 2 * * *',
  'ANALYZE cost_records, task_records, education_records;'
);
```

### 9.2 í”„ë¡ íŠ¸ì—”ë“œ ìµœì í™”

```typescript
// hooks/useOptimizedQuery.ts
import { useQuery } from '@tanstack/react-query'
import { supabase } from '@/lib/supabase'

export function useOptimizedCostRecords() {
  return useQuery({
    queryKey: ['cost-records'],
    queryFn: async () => {
      const startTime = Date.now()
      
      const { data, error } = await supabase
        .from('cost_records')
        .select(`
          id, code, content, amount, status, team,
          assignee:user_profiles(name)
        `)
        .order('registration_date', { ascending: false })
        .limit(50) // í˜ì´ì§€ë„¤ì´ì…˜
      
      // ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
      MonitoringService.trackQueryPerformance('cost-records-list', startTime)
      
      if (error) throw error
      return data
    },
    staleTime: 5 * 60 * 1000, // 5ë¶„ê°„ ìºì‹œ ìœ ì§€
    gcTime: 10 * 60 * 1000, // 10ë¶„ í›„ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
  })
}

// ë¬´í•œ ìŠ¤í¬ë¡¤ êµ¬í˜„
export function useInfiniteCostRecords() {
  return useInfiniteQuery({
    queryKey: ['cost-records-infinite'],
    queryFn: async ({ pageParam = 0 }) => {
      const { data, error } = await supabase
        .from('cost_records')
        .select('*')
        .range(pageParam * 20, (pageParam + 1) * 20 - 1)
        .order('registration_date', { ascending: false })
      
      if (error) throw error
      return {
        data,
        nextCursor: data.length === 20 ? pageParam + 1 : undefined
      }
    },
    getNextPageParam: (lastPage) => lastPage.nextCursor
  })
}
```

## ğŸ¯ 10. ê²°ë¡  ë° ê¸°ëŒ€ íš¨ê³¼

### 10.1 êµ¬í˜„ í›„ ê¸°ëŒ€ íš¨ê³¼

#### ê¸°ìˆ ì  ê°œì„ ì‚¬í•­
1. **í™•ì¥ì„±**: PostgreSQL ê¸°ë°˜ìœ¼ë¡œ ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ê°€ëŠ¥
2. **ì‹¤ì‹œê°„ì„±**: Realtime êµ¬ë…ìœ¼ë¡œ ì¦‰ê°ì ì¸ ë°ì´í„° ë™ê¸°í™”
3. **ë³´ì•ˆì„±**: RLS ê¸°ë°˜ ì„¸ë°€í•œ ì ‘ê·¼ ì œì–´
4. **ì„±ëŠ¥**: ì¸ë±ì‹±ê³¼ ì¿¼ë¦¬ ìµœì í™”ë¡œ ë¹ ë¥¸ ì‘ë‹µ ì‹œê°„

#### ë¹„ì¦ˆë‹ˆìŠ¤ ê°œì„ ì‚¬í•­
1. **í˜‘ì—… íš¨ìœ¨ì„±**: ì‹¤ì‹œê°„ ë°ì´í„° ê³µìœ ë¡œ íŒ€ í˜‘ì—… í–¥ìƒ
2. **ë°ì´í„° ì‹ ë¢°ì„±**: ACID ì†ì„± ë³´ì¥ìœ¼ë¡œ ë°ì´í„° ë¬´ê²°ì„± í™•ë³´
3. **ê°ì‚¬ ì¶”ì **: ëª¨ë“  ë³€ê²½ì‚¬í•­ ë¡œê¹…ìœ¼ë¡œ íˆ¬ëª…ì„± í™•ë³´
4. **ëª¨ë°”ì¼ ì§€ì›**: ë°˜ì‘í˜• ì„¤ê³„ë¡œ ëª¨ë“  ê¸°ê¸°ì—ì„œ ì ‘ê·¼ ê°€ëŠ¥

### 10.2 ì¶”ê°€ ê°œì„  ê³„íš

#### ë‹¨ê¸° ê³„íš (3-6ê°œì›”)
- **ê³ ê¸‰ ê²€ìƒ‰**: Full-text search êµ¬í˜„
- **ì•Œë¦¼ ì‹œìŠ¤í…œ**: ì´ë©”ì¼/í‘¸ì‹œ ì•Œë¦¼ êµ¬í˜„
- **ëŒ€ì‹œë³´ë“œ ê°•í™”**: ì‹¤ì‹œê°„ ì°¨íŠ¸ ë° ìœ„ì ¯
- **ëª¨ë°”ì¼ ì•±**: React Native ê¸°ë°˜ ì•± ê°œë°œ

#### ì¤‘ì¥ê¸° ê³„íš (6ê°œì›”-1ë…„)
- **AI í†µí•©**: ë¹„ìš© ì˜ˆì¸¡ ë° ì—…ë¬´ ìë™í™”
- **ì›Œí¬í”Œë¡œìš°**: ìŠ¹ì¸ í”„ë¡œì„¸ìŠ¤ ìë™í™”
- **API ê°œë°©**: ì™¸ë¶€ ì‹œìŠ¤í…œ ì—°ë™ ì§€ì›
- **ê¸€ë¡œë²Œí™”**: ë‹¤êµ­ì–´ ì§€ì› ë° íƒ€ì„ì¡´ ì²˜ë¦¬

### 10.3 ë¦¬ìŠ¤í¬ ê´€ë¦¬

#### ê¸°ìˆ ì  ë¦¬ìŠ¤í¬
- **ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨**: ë‹¨ê³„ë³„ ê²€ì¦ ë° ë¡¤ë°± ê³„íš ìˆ˜ë¦½
- **ì„±ëŠ¥ ì €í•˜**: ë¡œë“œ í…ŒìŠ¤íŒ… ë° ì ì§„ì  ìµœì í™”
- **ë³´ì•ˆ ì·¨ì•½ì **: ì •ê¸°ì  ë³´ì•ˆ ê°ì‚¬ ë° ì—…ë°ì´íŠ¸

#### ìš´ì˜ ë¦¬ìŠ¤í¬  
- **ì‚¬ìš©ì ì ì‘**: ì¶©ë¶„í•œ êµìœ¡ ë° ê°€ì´ë“œ ì œê³µ
- **ë°ì´í„° ì†ì‹¤**: ì •ê¸° ë°±ì—… ë° ë³µêµ¬ í…ŒìŠ¤íŠ¸
- **ì„œë¹„ìŠ¤ ì¤‘ë‹¨**: ëª¨ë‹ˆí„°ë§ ë° ì•Œë¦¼ ì‹œìŠ¤í…œ êµ¬ì¶•

---

## ğŸ“š ë¶€ë¡

### A. í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ëª©ë¡

```json
{
  "dependencies": {
    "@supabase/supabase-js": "^2.39.3",
    "@tanstack/react-query": "^5.62.16",
    "next": "15.1.6",
    "react": "18.3.1",
    "typescript": "5.7.3"
  },
  "devDependencies": {
    "supabase": "^1.123.4"
  }
}
```

### B. ìœ ìš©í•œ Supabase CLI ëª…ë ¹ì–´

```bash
# í”„ë¡œì íŠ¸ ì´ˆê¸°í™”
supabase init

# ë¡œì»¬ ê°œë°œ í™˜ê²½ ì‹œì‘
supabase start

# ë§ˆì´ê·¸ë ˆì´ì…˜ ìƒì„±
supabase migration new migration_name

# ë°ì´í„°ë² ì´ìŠ¤ ë¦¬ì…‹
supabase db reset

# íƒ€ì… ìƒì„±
supabase gen types typescript --project-id YOUR_PROJECT_ID > types/database.types.ts

# í•¨ìˆ˜ ë°°í¬
supabase functions deploy function_name

# ë¡œê·¸ í™•ì¸
supabase functions logs function_name
```

### C. ì°¸ê³  ë§í¬

- [Supabase ê³µì‹ ë¬¸ì„œ](https://supabase.com/docs)
- [PostgreSQL ê³µì‹ ë¬¸ì„œ](https://www.postgresql.org/docs/)
- [Next.js ê³µì‹ ë¬¸ì„œ](https://nextjs.org/docs)
- [React Query ê³µì‹ ë¬¸ì„œ](https://tanstack.com/query/latest)

---

*ì´ ë¬¸ì„œëŠ” Nexwork Frontend í”„ë¡œì íŠ¸ì˜ Supabase ë°±ì—”ë“œ êµ¬ì¶•ì„ ìœ„í•œ í¬ê´„ì ì¸ ê³„íšì„œì…ë‹ˆë‹¤. êµ¬í˜„ ê³¼ì •ì—ì„œ ì„¸ë¶€ ì‚¬í•­ì€ ìš”êµ¬ì‚¬í•­ì— ë”°ë¼ ì¡°ì •ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.*